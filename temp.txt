
📁 /Users/juliusolsson/Desktop/Development/lazy-llms
============================================================

## Structure:

mcp/
├── src/
│   ├── tools/
│   ├── __init__.py (0.0B)
│   ├── config.py (4.3KB)
│   ├── database.py (31.8KB)
│   ├── git_integration.py (1.2KB)
│   ├── models.py (25.0KB)
│   ├── server.py (61.5KB)
│   └── utils.py (27.4KB)
├── Makefile (3.0KB)
└── requirements.txt (117.0B)
scripts/
└── quickstart.py (4.0KB)
src/
├── jira_lite/
│   ├── api/
│   │   └── __init__.py (9.7KB)
│   ├── models/
│   ├── __init__.py (0.0B)
│   ├── app.py (7.6KB)
│   ├── config.py (413.0B)
│   ├── init_db.py (10.8KB)
│   ├── models.py (11.3KB)
│   ├── repositories.py (18.0KB)
│   ├── storage.py (7.0KB)
│   └── utils.py (2.7KB)
├── tools/
│   └── __init__.py (0.0B)
└── __init__.py (0.0B)
tests/
docker-compose.yml (931.0B)
Dockerfile (965.0B)
Makefile (6.8KB)
QUICKSTART_INSTRUCTIONS.md (1.5KB)
requirements.txt (141.0B)

## File Contents:


### mcp/src/__init__.py
```

```

### mcp/src/config.py
```
"""Configuration for PM MCP Server with proper first-run handling"""
import os
from pathlib import Path
from typing import Optional

class Config:
    """Server configuration with proper initialization"""

    # Database - delay initialization to avoid import-time failures
    _database_path: Optional[Path] = None

    @classmethod
    def get_database_path(cls) -> Path:
        """Get database path with fallback logic"""
        if cls._database_path is not None:
            return cls._database_path

        # Try environment variable first
        env_path = os.getenv("PM_DATABASE_PATH")
        if env_path:
            cls._database_path = Path(env_path)
            return cls._database_path

        # Try default location - align with repo data path
        default_path = Path(__file__).parent.parent.parent / "data" / "jira_lite.db"
        if default_path.exists():
            cls._database_path = default_path
            return cls._database_path

        # Try relative path from main project
        relative_path = Path(__file__).parent.parent.parent / "data" / "jira_lite.db"
        if relative_path.exists():
            cls._database_path = relative_path
            return cls._database_path

        # Return default anyway - will be created if needed
        cls._database_path = default_path
        return cls._database_path

    @classmethod
    def set_database_path(cls, path: str):
        """Set database path explicitly"""
        cls._database_path = Path(path)

    # Server settings
    DEFAULT_PORT = int(os.getenv("MCP_SERVER_PORT", "8848"))
    DEFAULT_HOST = os.getenv("MCP_SERVER_HOST", "127.0.0.1")
    DEFAULT_TRANSPORT = os.getenv("MCP_TRANSPORT", "stdio")

    # Project defaults
    DEFAULT_PROJECT_ID: Optional[str] = os.getenv("PM_DEFAULT_PROJECT_ID")
    DEFAULT_OWNER = os.getenv("PM_DEFAULT_OWNER", "agent:claude-code")

    @staticmethod
    def get_default_project_id() -> Optional[str]:
        """Get default project ID from environment"""
        return os.environ.get("PM_DEFAULT_PROJECT_ID")

    # Git settings
    GIT_USER_NAME = os.getenv("GIT_USER_NAME", "Claude Code Agent")
    GIT_USER_EMAIL = os.getenv("GIT_USER_EMAIL", "noreply@anthropic.com")

    # Limits
    MAX_ISSUES_PER_LIST = int(os.getenv("PM_MAX_ISSUES", "100"))
    MAX_WORKLOGS_PER_LIST = int(os.getenv("PM_MAX_WORKLOGS", "50"))
    MAX_FILE_SIZE_BYTES = 10 * 1024 * 1024  # 10MB

    # Security settings
    ALLOWED_GIT_COMMANDS = {
        "status", "log", "branch", "checkout", "add", "commit",
        "push", "pull", "fetch", "merge", "stash", "diff", "show"
    }

    @classmethod
    def validate(cls, strict: bool = False) -> tuple[bool, list[str]]:
        """
        Validate configuration with better error handling
        Returns (is_valid, warnings/errors)
        """
        warnings = []
        errors = []

        # Check database
        db_path = cls.get_database_path()
        if not db_path.exists():
            if strict:
                errors.append(f"Database not found at {db_path}")
            else:
                warnings.append(f"Database not found at {db_path} - will be created if needed")
        else:
            # Check if database is readable
            try:
                with open(db_path, 'rb') as f:
                    f.read(16)  # Read SQLite header
            except Exception as e:
                errors.append(f"Cannot read database at {db_path}: {e}")

        # Check git configuration
        if not cls.GIT_USER_EMAIL:
            warnings.append("GIT_USER_EMAIL not set - using default")

        # Check project defaults
        if not cls.DEFAULT_PROJECT_ID:
            warnings.append("PM_DEFAULT_PROJECT_ID not set - will use first available project")

        is_valid = len(errors) == 0
        return is_valid, warnings + errors

    @classmethod
    def get_summary(cls) -> dict:
        """Get configuration summary for debugging"""
        return {
            "database_path": str(cls.get_database_path()),
            "database_exists": cls.get_database_path().exists(),
            "default_project": cls.DEFAULT_PROJECT_ID,
            "default_owner": cls.DEFAULT_OWNER,
            "git_user": f"{cls.GIT_USER_NAME} <{cls.GIT_USER_EMAIL}>",
            "server": {
                "host": cls.DEFAULT_HOST,
                "port": cls.DEFAULT_PORT,
                "transport": cls.DEFAULT_TRANSPORT
            }
        }
```

### mcp/src/database.py
```
"""Database connection and repository layer for PM MCP Server - NO RAW SQL"""
import json
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Any, Optional, Union
from peewee import *
from peewee import fn
from config import Config
from utils import safe_json_loads

def _safe_json(val, default):
    """Safe JSON parsing with fallback"""
    if not val:
        return default
    try:
        if isinstance(val, (dict, list)):
            return val
        return json.loads(val)
    except Exception:
        return default

def _get_issue_field_json(issue, field_name):
    """Get JSON field from issue safely"""
    return _safe_json(getattr(issue, field_name, None), {})

def _get(obj, name, default=None):
    """Safe attribute getter"""
    return getattr(obj, name, default)

# Initialize database with delayed connection
db_proxy = DatabaseProxy()

class BaseModel(Model):
    """Base model with common functionality"""
    class Meta:
        database = db_proxy

    def to_dict(self) -> Dict[str, Any]:
        """Convert model to dictionary safely"""
        data = {}
        for field in self._meta.sorted_fields:
            value = getattr(self, field.name)
            if isinstance(value, datetime):
                data[field.name] = value.isoformat() + 'Z'
            elif hasattr(value, 'to_dict'):
                data[field.name] = value.to_dict()
            elif hasattr(value, 'id'):
                data[field.name] = str(value.id)
            else:
                data[field.name] = value
        return data

class Project(BaseModel):
    """Project model"""
    project_id = CharField(unique=True, index=True, max_length=64)
    project_slug = CharField(index=True, max_length=100)
    absolute_path = CharField(max_length=500)
    metadata = TextField(null=True)  # JSON
    created_utc = DateTimeField(index=True)
    updated_utc = DateTimeField(index=True)

    def get_metadata(self) -> Dict[str, Any]:
        """Safely parse metadata JSON"""
        if not self.metadata:
            return {}
        try:
            return json.loads(self.metadata)
        except (json.JSONDecodeError, TypeError):
            return {}

    @property
    def submodules(self) -> List[Dict[str, Any]]:
        return self.get_metadata().get('submodules', [])

    @property
    def vcs(self) -> Dict[str, Any]:
        return self.get_metadata().get('vcs', {})

class Issue(BaseModel):
    """Issue model with rich content"""
    project = ForeignKeyField(Project, backref='issues', on_delete='CASCADE')
    key = CharField(unique=True, index=True, max_length=50)
    title = CharField(index=True, max_length=200)
    type = CharField(index=True, max_length=20)
    status = CharField(index=True, max_length=20)
    priority = CharField(index=True, max_length=10)
    module = CharField(null=True, index=True, max_length=100)
    owner = CharField(null=True, index=True, max_length=100)
    external_id = CharField(null=True, index=True, max_length=100)

    # Rich content as JSON
    specification = TextField(null=True)
    planning = TextField(null=True)
    implementation = TextField(null=True)
    communication = TextField(null=True)
    analytics = TextField(null=True)

    created_utc = DateTimeField(index=True)
    updated_utc = DateTimeField(index=True)

    def get_json_field(self, field_name: str) -> Dict[str, Any]:
        """Safely parse JSON field"""
        field_value = getattr(self, field_name, None)
        if not field_value:
            return {}
        try:
            return json.loads(field_value)
        except (json.JSONDecodeError, TypeError):
            return {}

    @property
    def description(self) -> str:
        return self.get_json_field('specification').get('description', '')

    @property
    def acceptance_criteria(self) -> List[str]:
        return self.get_json_field('specification').get('acceptance_criteria', [])

    @property
    def dependencies(self) -> List[str]:
        return self.get_json_field('planning').get('dependencies', [])

    @property
    def estimated_effort(self) -> str:
        return self.get_json_field('planning').get('estimated_effort', '')

    @property
    def complexity(self) -> str:
        return self.get_json_field('planning').get('complexity', 'Medium')

    @property
    def branch_hint(self) -> str:
        return self.get_json_field('implementation').get('branch_hint', '')

    def to_rich_dict(self) -> Dict[str, Any]:
        """Convert to dict with all JSON properties expanded"""
        data = self.to_dict()
        data.update({
            'description': self.description,
            'acceptance_criteria': self.acceptance_criteria,
            'dependencies': self.dependencies,
            'estimated_effort': self.estimated_effort,
            'complexity': self.complexity,
            'branch_hint': self.branch_hint,
            'project_slug': self.project.project_slug,
            'project_path': self.project.absolute_path
        })
        return data

class Task(BaseModel):
    """Task model"""
    issue = ForeignKeyField(Issue, backref='tasks', on_delete='CASCADE')
    task_id = CharField(unique=True, index=True, max_length=100)
    title = CharField(max_length=200)
    status = CharField(index=True, max_length=20)
    assignee = CharField(null=True, index=True, max_length=100)
    details = TextField(null=True)  # JSON
    created_utc = DateTimeField(index=True)
    updated_utc = DateTimeField(index=True)

    def get_details(self) -> Dict[str, Any]:
        """Safely parse details JSON"""
        if not self.details:
            return {}
        try:
            return json.loads(self.details)
        except (json.JSONDecodeError, TypeError):
            return {}

    @property
    def checklist(self) -> List[Dict[str, Any]]:
        return self.get_details().get('checklist', [])

    @property
    def notes(self) -> str:
        return self.get_details().get('notes', '')

class WorkLog(BaseModel):
    """WorkLog model"""
    issue = ForeignKeyField(Issue, backref='worklogs', on_delete='CASCADE')
    task = ForeignKeyField(Task, backref='worklogs', on_delete='SET NULL', null=True)
    agent = CharField(index=True, max_length=100)
    timestamp_utc = DateTimeField(index=True)
    activity = CharField(index=True, max_length=50)
    summary = TextField()
    artifacts = TextField(null=True)  # JSON
    context = TextField(null=True)  # JSON

    def get_artifacts(self) -> List[Dict[str, Any]]:
        """Safely parse artifacts JSON"""
        if not self.artifacts:
            return []
        try:
            return json.loads(self.artifacts)
        except (json.JSONDecodeError, TypeError):
            return []

    def get_context(self) -> Dict[str, Any]:
        """Safely parse context JSON"""
        if not self.context:
            return {}
        try:
            return json.loads(self.context)
        except (json.JSONDecodeError, TypeError):
            return {}

class PMDatabase:
    """Database operations wrapper with proper Peewee usage - NO RAW SQL"""

    _db_initialized = False

    # ---------- Converters (models -> dicts) ----------
    @staticmethod
    def _project_to_dict(p: Project) -> Dict[str, Any]:
        """Convert Project model to dict"""
        meta = safe_json_loads(getattr(p, "metadata", None))
        return {
            "project_id": p.project_id,
            "project_slug": p.project_slug,
            "absolute_path": p.absolute_path,
            "metadata": meta,
            "created_utc": p.created_utc.isoformat() + "Z" if isinstance(p.created_utc, datetime) else None,
            "updated_utc": p.updated_utc.isoformat() + "Z" if isinstance(p.updated_utc, datetime) else None,
        }

    @staticmethod
    def _issue_to_dict(i: Issue) -> Dict[str, Any]:
        """Convert Issue model to dict"""
        spec = safe_json_loads(getattr(i, "specification", None))
        plan = safe_json_loads(getattr(i, "planning", None))
        impl = safe_json_loads(getattr(i, "implementation", None))
        comm = safe_json_loads(getattr(i, "communication", None))
        anal = safe_json_loads(getattr(i, "analytics", None))
        return {
            "key": i.key,
            "title": i.title,
            "type": i.type,
            "status": i.status,
            "priority": i.priority,
            "module": i.module,
            "owner": i.owner,
            "project_id": getattr(i.project, "project_id", None),
            "description": spec.get("description", ""),
            "acceptance_criteria": spec.get("acceptance_criteria", []),
            "technical_approach": spec.get("technical_approach", ""),
            "dependencies": plan.get("dependencies", []),
            "estimated_effort": plan.get("estimated_effort"),
            "complexity": plan.get("complexity"),
            "branch_hint": impl.get("branch_hint"),
            "commit_preamble": impl.get("commit_preamble"),
            "commit_trailer": impl.get("commit_trailer"),
            "links": impl.get("links") or {},
            "created_utc": i.created_utc.isoformat() + "Z" if isinstance(i.created_utc, datetime) else None,
            "updated_utc": i.updated_utc.isoformat() + "Z" if isinstance(i.updated_utc, datetime) else None,
        }

    @staticmethod
    def _worklog_to_dict(w: WorkLog) -> Dict[str, Any]:
        """Convert WorkLog model to dict"""
        artifacts = []
        ctx = {}
        try:
            artifacts = json.loads(w.artifacts) if w.artifacts else []
        except Exception:
            artifacts = []
        try:
            ctx = json.loads(w.context) if w.context else {}
        except Exception:
            ctx = {}
        return {
            "issue_key": getattr(w.issue, "key", None),
            "task_id": getattr(getattr(w, "task", None), "task_id", None),
            "agent": w.agent,
            "activity": w.activity,
            "summary": w.summary,
            "artifacts": artifacts,
            "context": ctx,
            "timestamp_utc": w.timestamp_utc.isoformat() + "Z" if isinstance(w.timestamp_utc, datetime) else None,
        }

    @classmethod
    def initialize(cls):
        """Initialize database connection"""
        if cls._db_initialized:
            return

        # Create database path if needed
        db_path = Config.get_database_path()
        db_path.parent.mkdir(parents=True, exist_ok=True)

        # Initialize database
        database = SqliteDatabase(str(db_path))
        db_proxy.initialize(database)

        # Create tables if needed
        database.create_tables([Project, Issue, Task, WorkLog], safe=True)
        cls._db_initialized = True

    @classmethod
    def connect(cls):
        """Connect to database"""
        if not cls._db_initialized:
            cls.initialize()
        if db_proxy.is_closed():
            db_proxy.connect()

    @classmethod
    def close(cls):
        """Close database connection"""
        if not db_proxy.is_closed():
            db_proxy.close()

    @classmethod
    def get_project(cls, project_id: str) -> Optional[Project]:
        """Get project by ID - returns Peewee model"""
        if not project_id:
            return None
        try:
            return Project.get(Project.project_id == project_id)
        except DoesNotExist:
            return None

    @classmethod
    def get_all_projects(cls) -> List[Project]:
        """Get all projects - returns list of Peewee models"""
        return list(Project.select().order_by(Project.project_slug))

    @classmethod
    def get_issue(cls, issue_key: str) -> Optional[Issue]:
        """Get issue by key - returns Peewee model"""
        if not issue_key:
            return None
        try:
            return Issue.get(Issue.key == issue_key)
        except DoesNotExist:
            return None

    @classmethod
    def get_issue_scoped(cls, project_id: str, issue_key: str) -> Optional[Issue]:
        """Fetch an issue by key but only if it belongs to project_id."""
        if not project_id or not issue_key:
            return None
        try:
            issue = Issue.get(Issue.key == issue_key)
            # Verify it belongs to the right project
            if issue.project.project_id != project_id:
                return None
            return issue
        except DoesNotExist:
            return None

    @classmethod
    def find_issues(cls, project_id: str, **filters) -> List[Issue]:
        """Find issues with filters - returns Peewee models"""
        if not project_id:
            return []
        query = (Issue.select()
                .join(Project)
                .where(Project.project_id == project_id))

        status = filters.get('status')
        priority = filters.get('priority')
        module = filters.get('module')
        search = filters.get('q') or filters.get('query')

        if status:
            query = query.where(Issue.status == status)
        if priority:
            query = query.where(Issue.priority == priority)
        if module:
            query = query.where(Issue.module == module)
        if search:
            query = query.where(
                (Issue.title.contains(search)) |
                (Issue.specification.contains(search)) |
                (Issue.planning.contains(search))
            )
        return list(query.order_by(Issue.updated_utc.desc()))

    @classmethod
    def get_issue_with_relations(cls, issue_key: str) -> Optional[Dict[str, Any]]:
        """Get issue with tasks and worklogs using Peewee relationships"""
        try:
            issue = Issue.get(Issue.key == issue_key)

            # Use Peewee relationships - no raw SQL!
            tasks = []
            for task in issue.tasks:  # Auto lazy-loaded backref
                task_data = task.to_dict()
                task_data.update({
                    'checklist': task.checklist,
                    'notes': task.notes
                })
                tasks.append(task_data)

            worklogs = []
            for worklog in issue.worklogs.order_by(WorkLog.timestamp_utc.desc()).limit(20):  # Auto lazy-loaded
                worklog_data = worklog.to_dict()
                worklog_data.update({
                    'artifacts': worklog.get_artifacts(),
                    'context': worklog.get_context()
                })
                worklogs.append(worklog_data)

            return {
                'issue': issue.to_rich_dict(),
                'tasks': tasks,
                'worklogs': worklogs,
                'project': {
                    'project_id': issue.project.project_id,
                    'project_slug': issue.project.project_slug,
                    'absolute_path': issue.project.absolute_path
                }
            }
        except DoesNotExist:
            return None

    @classmethod
    def search_issues(cls, query_text: str, project_id: Optional[str] = None, limit: int = 20) -> List[Dict[str, Any]]:
        """Full-text search using Peewee queries"""
        # Build search conditions
        search_conditions = (
            Issue.title.contains(query_text) |
            Issue.specification.contains(query_text) |
            Issue.planning.contains(query_text) |
            Issue.implementation.contains(query_text)
        )

        query = Issue.select().where(search_conditions)

        if project_id:
            query = query.join(Project).where(Project.project_id == project_id)

        query = query.order_by(Issue.updated_utc.desc()).limit(limit)
        return [issue.to_rich_dict() for issue in query]

    @classmethod
    def create_issue(cls, input_model) -> Issue:
        """Create issue from input model - returns Peewee model"""
        project = cls.get_project(input_model.project_id)
        if project is None:
            raise ValueError("Invalid or missing project_id")

        now = datetime.utcnow()

        # Generate issue key
        issue_key = cls.generate_issue_key(project.project_slug)

        spec = {
            "description": input_model.description,
            "acceptance_criteria": getattr(input_model, 'acceptance_criteria', []) or [],
            "technical_approach": getattr(input_model, "technical_approach", "") or ""
        }
        planning = {
            "dependencies": getattr(input_model, 'dependencies', []) or [],
            "stakeholders": getattr(input_model, "stakeholders", []) or [],
            "estimated_effort": getattr(input_model, "estimated_effort", None),
            "complexity": getattr(input_model, "complexity", "Medium"),
            "risks": getattr(input_model, "risks", []) or []
        }
        implementation = {
            "branch_hint": getattr(input_model, "branch_hint", None),
            "commit_preamble": f"[pm {issue_key}]",
            "commit_trailer": f"PM: {issue_key}",
        }

        return Issue.create(
            project=project,
            key=issue_key,
            title=input_model.title,
            type=input_model.type,
            status="proposed",
            priority=getattr(input_model, 'priority', 'P3') or "P3",
            module=getattr(input_model, "module", None),
            owner=getattr(input_model, "owner", None),
            specification=json.dumps(spec),
            planning=json.dumps(planning),
            implementation=json.dumps(implementation),
            created_utc=now,
            updated_utc=now,
        )

    @classmethod
    def create_or_update_task(cls, task_data: Dict[str, Any]) -> Dict[str, Any]:
        """Create or update task using Peewee models"""
        # Find issue
        try:
            issue = Issue.get(Issue.key == task_data['issue_key'])
        except DoesNotExist:
            raise ValueError(f"Issue {task_data['issue_key']} not found")

        # Prepare details JSON
        details = json.dumps({
            'checklist': task_data.get('checklist', []),
            'notes': task_data.get('notes', ''),
            'time_estimate': task_data.get('time_estimate', '')
        })

        try:
            # Update existing task
            task = Task.get(Task.task_id == task_data['task_id'])
            task.title = task_data.get('title', task.title)
            task.status = task_data.get('status', task.status)
            task.assignee = task_data.get('assignee', task.assignee)
            task.details = details
            task.updated_utc = datetime.utcnow()
            task.save()
        except DoesNotExist:
            # Create new task
            task = Task.create(
                issue=issue,
                task_id=task_data['task_id'],
                title=task_data['title'],
                status=task_data.get('status', 'todo'),
                assignee=task_data.get('assignee'),
                details=details,
                created_utc=datetime.utcnow(),
                updated_utc=datetime.utcnow()
            )

        result = task.to_dict()
        result.update({
            'checklist': task.checklist,
            'notes': task.notes,
            'issue_key': issue.key
        })
        return result

    @classmethod
    def get_my_queue(cls, project_id: str, owner: Optional[str] = None, limit: int = 20) -> List[Issue]:
        """Get work queue - returns Peewee models"""
        if not project_id:
            return []
        query = (Issue.select()
                .join(Project)
                .where(Project.project_id == project_id))
        if owner:
            query = query.where(Issue.owner == owner)
        query = (query.where(Issue.status.in_(['proposed', 'in_progress']))
                .order_by(Issue.priority.asc(), Issue.updated_utc.desc())
                .limit(limit))
        return list(query)

    @classmethod
    def get_blocked_issues(cls, project_id: Optional[str] = None) -> List[Dict[str, Any]]:
        """Get blocked issues using Peewee query"""
        query = Issue.select().where(Issue.status == 'blocked')

        if project_id:
            query = query.join(Project).where(Project.project_id == project_id)

        return [issue.to_rich_dict() for issue in query.order_by(Issue.updated_utc.desc())]

    @classmethod
    def get_recent_worklogs(cls, issue_key: Optional[str] = None,
                           project_id: Optional[str] = None, limit: int = 20) -> List[Dict[str, Any]]:
        """Get recent worklogs using Peewee relationships"""
        query = WorkLog.select()

        if issue_key:
            query = query.join(Issue).where(Issue.key == issue_key)
        elif project_id:
            query = query.join(Issue).join(Project).where(Project.project_id == project_id)

        worklogs = query.order_by(WorkLog.timestamp_utc.desc()).limit(limit)

        result = []
        for worklog in worklogs:
            data = worklog.to_dict()
            data.update({
                'artifacts': worklog.get_artifacts(),
                'context': worklog.get_context(),
                'issue_key': worklog.issue.key
            })
            result.append(data)
        return result

    @classmethod
    def update_issue_planning_estimate(cls, issue, effort: str, complexity: Optional[str], reasoning: Optional[str]):
        """Update issue planning with estimates"""
        planning = _get_issue_field_json(issue, 'planning')
        planning["estimated_effort"] = effort
        if complexity:
            planning["complexity"] = complexity
        if reasoning:
            notes = planning.get("estimate_notes", [])
            notes.append({
                "timestamp_utc": datetime.utcnow().isoformat() + "Z",
                "reasoning": reasoning
            })
            planning["estimate_notes"] = notes
        issue.planning = json.dumps(planning)
        issue.updated_utc = datetime.utcnow()
        issue.save()
        return issue

    @classmethod
    def create_task(cls, issue, title: str, assignee: Optional[str], details: Optional[Dict[str, Any]]):
        """Create task with auto-generated ID"""
        # FIX: use .count() instead of fn.COUNT()
        existing = Task.select().where(Task.issue == issue).count() or 0
        task_id = f"{issue.key}-T{existing + 1}"
        t = Task.create(
            issue=issue,
            task_id=task_id,
            title=title,
            status="todo",
            assignee=assignee,
            details=json.dumps(details or {}),
            created_utc=datetime.utcnow(),
            updated_utc=datetime.utcnow(),
        )
        return t

    @classmethod
    def get_task(cls, task_id: str) -> Optional[Task]:
        """Get task by ID"""
        try:
            return Task.get(Task.task_id == task_id)
        except DoesNotExist:
            return None

    @classmethod
    def update_task(cls, task, title=None, status=None, assignee=None, details=None):
        """Update task fields"""
        if title is not None:
            task.title = title
        if status is not None:
            task.status = status
        if assignee is not None:
            task.assignee = assignee
        if details is not None:
            task.details = json.dumps(details)
        task.updated_utc = datetime.utcnow()
        task.save()
        return task

    @classmethod
    def get_issues(cls, project_id: Optional[str] = None,
                   owner: Optional[str] = None,
                   status: Optional[str] = None,
                   priority: Optional[str] = None,
                   module: Optional[str] = None,
                   limit: int = 1000) -> List[Dict[str, Any]]:
        """
        Return issues as rich dicts, optionally filtered.
        This is a dict-returning convenience wrapper used by server.py.
        """
        query = Issue.select()
        if project_id:
            query = query.join(Project).where(Project.project_id == project_id)
        if owner:
            query = query.where(Issue.owner == owner)
        if status:
            query = query.where(Issue.status == status)
        if priority:
            query = query.where(Issue.priority == priority)
        if module:
            query = query.where(Issue.module == module)
        query = query.order_by(Issue.updated_utc.desc()).limit(limit)
        return [i.to_rich_dict() for i in query]

    @classmethod
    def create_or_update_issue(cls, data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Update a single issue by key with incoming dict fields, mirroring IssueRepository logic.
        Returns a rich dict.
        """
        if "key" not in data:
            raise ValueError("create_or_update_issue requires 'key'")
        issue = cls.get_issue(data["key"])
        now = datetime.utcnow()

        # Prepare JSON fields
        spec = _safe_json(getattr(issue, "specification", None), {}) if issue else {}
        plan = _safe_json(getattr(issue, "planning", None), {}) if issue else {}
        impl = _safe_json(getattr(issue, "implementation", None), {}) if issue else {}

        # Merge incoming values
        if "description" in data or "acceptance_criteria" in data or "technical_approach" in data:
            spec.update({
                "description": data.get("description", spec.get("description", "")),
                "acceptance_criteria": data.get("acceptance_criteria", spec.get("acceptance_criteria", [])),
                "technical_approach": data.get("technical_approach", spec.get("technical_approach", "")),
            })

        if any(k in data for k in ("dependencies", "stakeholders", "estimated_effort", "complexity", "risks")):
            plan.update({
                "dependencies": data.get("dependencies", plan.get("dependencies", [])),
                "stakeholders": data.get("stakeholders", plan.get("stakeholders", [])),
                "estimated_effort": data.get("estimated_effort", plan.get("estimated_effort", None)),
                "complexity": data.get("complexity", plan.get("complexity", "Medium")),
                "risks": data.get("risks", plan.get("risks", [])),
            })

        if any(k in data for k in ("branch_hint", "commit_preamble", "commit_trailer", "links")):
            impl.update({
                "branch_hint": data.get("branch_hint", impl.get("branch_hint", None)),
                "commit_preamble": data.get("commit_preamble", impl.get("commit_preamble", None)),
                "commit_trailer": data.get("commit_trailer", impl.get("commit_trailer", None)),
                "links": data.get("links", impl.get("links", {})) or {},
            })

        if issue:
            # Update scalar fields
            for f in ("title", "type", "status", "priority", "module", "owner", "external_id"):
                if f in data and data[f] is not None:
                    setattr(issue, f, data[f])
            issue.specification = json.dumps(spec)
            issue.planning = json.dumps(plan)
            issue.implementation = json.dumps(impl)
            issue.updated_utc = now
            issue.save()
        else:
            # Need a project to create a new one
            project_id = data.get("project_id")
            project = cls.get_project(project_id) if project_id else None
            if not project:
                raise ValueError("Project not found for issue creation")
            issue = Issue.create(
                project=project,
                key=data["key"],
                title=data["title"],
                type=data["type"],
                status=data.get("status", "proposed"),
                priority=data.get("priority", "P3"),
                module=data.get("module"),
                owner=data.get("owner"),
                external_id=data.get("external_id"),
                specification=json.dumps(spec),
                planning=json.dumps(plan),
                implementation=json.dumps(impl),
                created_utc=now,
                updated_utc=now,
            )

        return issue.to_rich_dict()

    @classmethod
    def add_worklog(cls, data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Convenience wrapper expected by server.py.
        Creates a WorkLog from dict and returns a dict.
        """
        issue = cls.get_issue(data["issue_key"])
        if not issue:
            raise ValueError(f"Issue not found: {data['issue_key']}")

        task = None
        if data.get("task_id"):
            task = cls.get_task(data["task_id"])

        wl = WorkLog.create(
            issue=issue,
            task=task,
            agent=data.get("agent", "agent:claude-code"),
            timestamp_utc=datetime.utcnow(),
            activity=data["activity"],
            summary=data["summary"],
            artifacts=json.dumps(data.get("artifacts") or []),
            context=json.dumps(data.get("context") or {}),
        )
        return wl.to_dict()

    @classmethod
    def append_worklog(cls, issue, agent: str, activity: str, summary: str,
                      artifacts: Optional[List[Dict[str, Any]]], context: Optional[Dict[str, Any]],
                      task=None):
        """Add worklog entry"""
        wl = WorkLog.create(
            issue=issue,
            task=task,
            agent=agent,
            timestamp_utc=datetime.utcnow(),
            activity=activity,
            summary=summary,
            artifacts=json.dumps(artifacts or []),
            context=json.dumps(context or {}),
        )
        return wl

    @classmethod
    def project_metrics(cls, project):
        """Calculate project metrics"""
        issues = list(project.issues)
        status_counts = {}
        priority_counts = {}
        module_counts = {}
        for i in issues:
            status_counts[i.status] = status_counts.get(i.status, 0) + 1
            priority_counts[i.priority] = priority_counts.get(i.priority, 0) + 1
            if i.module:
                module_counts[i.module] = module_counts.get(i.module, 0) + 1

        recent_work = (WorkLog
                      .select()
                      .join(Issue)
                      .where(Issue.project == project)
                      .order_by(WorkLog.timestamp_utc.desc())
                      .limit(20))
        recent = []
        for w in recent_work:
            recent.append({
                "issue_key": w.issue.key,
                "task_id": w.task.task_id if w.task else None,
                "agent": w.agent,
                "activity": w.activity,
                "summary": w.summary,
                "timestamp_utc": w.timestamp_utc.isoformat() + "Z",
            })

        return {
            "counts": {
                "total": len(issues),
                "by_status": status_counts,
                "by_priority": priority_counts,
                "by_module": module_counts,
            },
            "recent_work": recent,
        }

    @classmethod
    def owner_capacity(cls, project):
        """Get capacity by owner"""
        rows = (Issue
               .select(Issue.owner, fn.COUNT(Issue.id).alias('count'))
               .where(Issue.project == project)
               .group_by(Issue.owner))
        result = []
        for r in rows:
            result.append({"owner": r.owner, "issue_count": r.count})
        return result

    @classmethod
    def generate_issue_key(cls, project_slug: str) -> str:
        """Generate unique issue key with proper collision handling"""
        # Get max issue number for this project to avoid races
        prefix = project_slug.upper()[:4].replace('-', '')
        if not prefix:
            prefix = "PROJ"

        # Use date-based format
        date_part = datetime.now().strftime("%Y%m")

        # Find max number for this month to avoid collisions
        pattern = f"{prefix}-{date_part}-%"
        existing = (Issue.select()
                   .where(Issue.key.startswith(f"{prefix}-{date_part}-"))
                   .order_by(Issue.key.desc())
                   .limit(1))

        max_num = 0
        for issue in existing:
            try:
                parts = issue.key.split('-')
                if len(parts) >= 3:
                    max_num = max(max_num, int(parts[2]))
            except (ValueError, IndexError):
                pass

        return f"{prefix}-{date_part}-{max_num + 1:03d}"

# Context manager for database operations
class DatabaseSession:
    """Context manager for database operations"""
    def __enter__(self):
        PMDatabase.connect()
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        PMDatabase.close()
```

### mcp/src/git_integration.py
```
"""Git integration helpers with security"""
from typing import Dict, Any
from utils import run_git

def git_status(repo_path: str) -> Dict[str, Any]:
    """Return porcelain git status for parsable output"""
    return run_git(repo_path, ["status", "--porcelain=v1"])

def git_current_branch(repo_path: str) -> Dict[str, Any]:
    """Get current branch name"""
    return run_git(repo_path, ["rev-parse", "--abbrev-ref", "HEAD"])

def git_push_current(repo_path: str, remote: str = "origin") -> Dict[str, Any]:
    """Push current HEAD to same branch name"""
    branch = git_current_branch(repo_path)
    if branch["rc"] != 0:
        return branch
    name = branch["out"].strip()
    return run_git(repo_path, ["push", remote, f"HEAD:{name}"])

def git_has_changes(repo_path: str) -> bool:
    """Check if repository has uncommitted changes"""
    status = git_status(repo_path)
    return status["rc"] == 0 and bool(status["out"].strip())

def git_branch_exists(repo_path: str, branch_name: str) -> bool:
    """Check if branch exists locally"""
    result = run_git(repo_path, ["branch", "--list", branch_name])
    return result["rc"] == 0 and branch_name in result["out"]
```

### mcp/src/models.py
```
"""Pydantic models for PM MCP Server tools with comprehensive validation"""
from typing import Optional, List, Dict, Any, Literal, Union
from pydantic import BaseModel, Field, validator
from datetime import datetime
import json

# =============== Standard Response Model ===============

class PMOperationResult(BaseModel):
    """Standard result for all PM operations"""
    success: bool = Field(description="Whether operation succeeded")
    message: str = Field(description="Human-readable result message")
    data: Optional[Dict[str, Any]] = Field(default=None, description="Operation-specific data")
    hints: Optional[List[str]] = Field(default=None, description="Helpful hints for next steps")
    timestamp: str = Field(default_factory=lambda: datetime.utcnow().isoformat() + 'Z')

    @classmethod
    def success_result(cls, message: str, data: Optional[Dict[str, Any]] = None,
                      hints: Optional[List[str]] = None) -> "PMOperationResult":
        """Create success result"""
        return cls(success=True, message=message, data=data, hints=hints)

    @classmethod
    def error_result(cls, message: str, details: Optional[Dict[str, Any]] = None) -> "PMOperationResult":
        """Create error result"""
        return cls(success=False, message=message, data=details)

# =============== Discovery Models ===============

class PMDocsInput(BaseModel):
    """Input for pm_docs tool"""
    section: Optional[Literal["overview", "commands", "workflow", "git", "troubleshooting"]] = Field(
        default=None,
        description="Specific section to retrieve. If omitted, returns comprehensive overview."
    )

class PMStatusInput(BaseModel):
    """Input for pm_status tool"""
    project_id: Optional[str] = Field(
        default=None,
        description="Project ID to get status for. Uses default if not specified."
    )
    verbose: bool = Field(
        default=False,
        description="Include detailed breakdowns of issues by status, priority, and module"
    )
    include_velocity: bool = Field(
        default=True,
        description="Include velocity metrics and trends"
    )

class ListIssuesInput(BaseModel):
    """Input for pm_list_issues tool"""
    project_id: Optional[str] = Field(
        default=None,
        description="Filter by project ID. Uses default if not specified."
    )
    status: Optional[Literal["proposed", "in_progress", "review", "done", "canceled", "blocked"]] = Field(
        default=None,
        description="Filter by issue status"
    )
    priority: Optional[Literal["P1", "P2", "P3", "P4", "P5"]] = Field(
        default=None,
        description="Filter by priority (P1=highest, P5=lowest)"
    )
    module: Optional[str] = Field(
        default=None,
        description="Filter by module/component name"
    )
    owner: Optional[str] = Field(
        default=None,
        description="Filter by owner (e.g., 'agent:claude-code')"
    )
    type: Optional[Literal["feature", "bug", "refactor", "chore", "spike"]] = Field(
        default=None,
        description="Filter by issue type"
    )
    limit: int = Field(
        default=20,
        ge=1,
        le=100,
        description="Maximum number of issues to return"
    )
    sort_by: Literal["updated", "created", "priority", "status"] = Field(
        default="updated",
        description="Sort order for results"
    )

class GetIssueInput(BaseModel):
    """Input for pm_get_issue tool"""
    issue_key: str = Field(
        description="Issue key (e.g., 'PROJ-001')",
        pattern=r"^[A-Z]+-\d+-\d{3}$"
    )
    project_id: Optional[str] = Field(
        default=None,
        description="Project scope (auto-resolved if omitted)"
    )
    include_tasks: bool = Field(
        default=True,
        description="Include associated tasks in response"
    )
    include_worklogs: bool = Field(
        default=True,
        description="Include work logs in response"
    )
    include_dependencies: bool = Field(
        default=True,
        description="Include dependency analysis"
    )

class SearchIssuesInput(BaseModel):
    """Input for pm_search_issues tool"""
    query: str = Field(
        description="Search query across titles, descriptions, and specifications",
        min_length=2
    )
    project_id: Optional[str] = Field(
        default=None,
        description="Limit search to specific project"
    )
    limit: int = Field(
        default=20,
        ge=1,
        le=100,
        description="Maximum number of results to return"
    )
    include_content: bool = Field(
        default=False,
        description="Include full content in results (slower but more context)"
    )

# =============== Planning Models ===============

class CreateIssueInput(BaseModel):
    """Input for pm_create_issue tool"""
    project_id: Optional[str] = Field(
        default=None,
        description="Project ID for the new issue. Uses default if not specified."
    )
    type: Literal["feature", "bug", "refactor", "chore", "spike"] = Field(
        description="Issue type determining workflow and branch naming"
    )
    title: str = Field(
        description="Brief, descriptive title for the issue",
        min_length=5,
        max_length=200
    )
    description: str = Field(
        description="Comprehensive description with business context, technical approach, and implementation details",
        min_length=20
    )
    priority: Literal["P1", "P2", "P3", "P4", "P5"] = Field(
        default="P3",
        description="Priority level (P1=critical/urgent, P5=nice-to-have)"
    )
    module: Optional[str] = Field(
        default=None,
        description="Module/component this issue belongs to"
    )
    acceptance_criteria: List[str] = Field(
        default_factory=list,
        description="List of specific, measurable acceptance criteria"
    )
    dependencies: List[str] = Field(
        default_factory=list,
        description="List of issue keys this depends on"
    )
    estimated_effort: Optional[str] = Field(
        default=None,
        description="Estimated effort (e.g., '1-2 days', '1 week', '3h')"
    )
    complexity: Literal["Low", "Medium", "High", "Very High"] = Field(
        default="Medium",
        description="Technical complexity assessment"
    )
    owner: Optional[str] = Field(
        default=None,
        description="Owner assignment (defaults to current agent)"
    )
    technical_approach: Optional[str] = Field(
        default=None,
        description="Detailed technical implementation approach"
    )
    stakeholders: List[str] = Field(
        default_factory=list,
        description="List of stakeholders to notify about this issue"
    )

class UpdateIssueInput(BaseModel):
    """Input for pm_update_issue tool"""
    issue_key: str = Field(
        description="Issue key to update",
        pattern=r"^[A-Z]+-\d+-\d{3}$"
    )
    title: Optional[str] = Field(default=None, min_length=5, max_length=200)
    description: Optional[str] = Field(default=None, min_length=20)
    status: Optional[Literal["proposed", "in_progress", "review", "done", "canceled", "blocked"]] = None
    priority: Optional[Literal["P1", "P2", "P3", "P4", "P5"]] = None
    module: Optional[str] = None
    owner: Optional[str] = None
    acceptance_criteria: Optional[List[str]] = None
    dependencies: Optional[List[str]] = None
    estimated_effort: Optional[str] = None
    complexity: Optional[Literal["Low", "Medium", "High", "Very High"]] = None
    notes: Optional[str] = Field(
        default=None,
        description="Notes about this update for the work log"
    )

class EstimateIssueInput(BaseModel):
    """Input for pm_estimate tool"""
    issue_key: str = Field(
        description="Issue key to estimate",
        pattern=r"^[A-Z]+-\d+-\d{3}$"
    )
    effort: str = Field(
        description="Effort estimate (e.g., '2-3 days', '1 week', '4h')"
    )
    complexity: Literal["Low", "Medium", "High", "Very High"] = Field(
        description="Complexity assessment"
    )
    confidence: Literal["Low", "Medium", "High"] = Field(
        default="Medium",
        description="Confidence level in the estimate"
    )
    reasoning: str = Field(
        description="Detailed reasoning for the estimate including approach and risks"
    )
    risks: List[str] = Field(
        default_factory=list,
        description="Identified risks that could affect the estimate"
    )

class RefineIssueInput(BaseModel):
    """Input for pm_refine_issue tool"""
    issue_key: str = Field(
        description="Issue key to refine",
        pattern=r"^[A-Z]+-\d+-\d{3}$"
    )
    aspect: Literal["requirements", "technical", "acceptance", "risks", "dependencies"] = Field(
        description="Aspect of the issue to refine"
    )
    suggestions: str = Field(
        description="Refinement suggestions, questions, or additional content",
        min_length=10
    )
    auto_apply: bool = Field(
        default=False,
        description="Automatically apply refinements without review"
    )

# =============== Execution Models ===============

class StartWorkInput(BaseModel):
    """Input for pm_start_work tool"""
    issue_key: str = Field(
        description="Issue key to start work on",
        pattern=r"^[A-Z]+-\d+-\d{3}$"
    )
    create_branch: bool = Field(
        default=True,
        description="Automatically create a git branch for this issue"
    )
    notes: Optional[str] = Field(
        default=None,
        description="Notes about starting this work"
    )
    validate_dependencies: bool = Field(
        default=True,
        description="Check that all dependencies are completed before starting"
    )

class LogWorkInput(BaseModel):
    """Input for pm_log_work tool"""
    issue_key: str = Field(
        description="Issue key to log work against",
        pattern=r"^[A-Z]+-\d+-\d{3}$"
    )
    activity: Literal["planning", "design", "code", "test", "review", "refactor", "debug", "document", "deploy", "blocked", "research"] = Field(
        description="Type of activity performed"
    )
    summary: str = Field(
        description="Summary of work performed including key decisions and outcomes",
        min_length=10
    )
    time_spent: Optional[str] = Field(
        default=None,
        description="Time spent (e.g., '2h', '30m', '1.5d')"
    )
    artifacts: Optional[Union[str, List[Dict[str, Any]]]] = Field(
        default_factory=list,
        description="List of artifacts or JSON string list"
    )
    blockers: Optional[str] = Field(
        default=None,
        description="Description of any blockers encountered"
    )
    task_id: Optional[str] = Field(
        default=None,
        description="Optional task ID if work is on a specific task"
    )
    decisions: Optional[str] = Field(
        default=None,
        description="Key technical or architectural decisions made"
    )

    @validator("artifacts", pre=True)
    def _normalize_artifacts(cls, v):
        """Handle flexible artifact input"""
        if v is None:
            return []
        if isinstance(v, list):
            return v
        # Try JSON string
        try:
            parsed = json.loads(v)
            return parsed if isinstance(parsed, list) else []
        except Exception:
            return []

class UpdateStatusInput(BaseModel):
    """Input for pm_update_status tool"""
    issue_key: str = Field(
        description="Issue key to update",
        pattern=r"^[A-Z]+-\d+-\d{3}$"
    )
    status: Literal["proposed", "in_progress", "review", "done", "canceled", "blocked"] = Field(
        description="New status with workflow validation"
    )
    notes: Optional[str] = Field(
        default=None,
        description="Notes about this status change for stakeholders"
    )
    notify: bool = Field(
        default=True,
        description="Whether to notify stakeholders about status change"
    )
    blocker_reason: Optional[str] = Field(
        default=None,
        description="Required if status is 'blocked' - reason for blocking"
    )

class CreateTaskInput(BaseModel):
    """Input for pm_create_task tool"""
    issue_key: str = Field(
        description="Parent issue key",
        pattern=r"^[A-Z]+-\d+-\d{3}$"
    )
    title: str = Field(
        description="Task title",
        min_length=5,
        max_length=200
    )
    checklist: List[str] = Field(
        default_factory=list,
        description="Checklist items for this task"
    )
    assignee: Optional[str] = Field(
        default=None,
        description="Task assignee (defaults to issue owner)"
    )
    notes: Optional[str] = Field(
        default=None,
        description="Additional notes for the task"
    )
    time_estimate: Optional[str] = Field(
        default=None,
        description="Time estimate for the task (e.g., '2h', '1d')"
    )
    details: Optional[Dict[str, Any]] = Field(
        default_factory=dict,
        description="Task metadata including checklist and notes"
    )
    status: Literal["todo", "doing", "blocked", "review", "done"] = Field(
        default="todo",
        description="Initial task status"
    )

class UpdateTaskInput(BaseModel):
    """Input for pm_update_task tool"""
    task_id: str = Field(
        description="Task ID (e.g., PROJ-001-T1)"
    )
    title: Optional[str] = Field(
        default=None,
        description="New task title"
    )
    status: Optional[str] = Field(
        default=None,
        description="New status: todo|doing|blocked|review|done"
    )
    assignee: Optional[str] = Field(
        default=None,
        description="New assignee"
    )
    details: Optional[Dict[str, Any]] = Field(
        default=None,
        description="Updated task metadata"
    )

# =============== Git Integration Models ===============

class GitStatusInput(BaseModel):
    """Input for pm_git_status tool"""
    issue_context: bool = Field(
        default=True,
        description="Include issue context for current branch"
    )
    show_suggestions: bool = Field(
        default=True,
        description="Show suggested next actions"
    )

class CreateBranchInput(BaseModel):
    """Input for pm_create_branch tool"""
    issue_key: str = Field(
        description="Issue key to create branch for",
        pattern=r"^[A-Z]+-\d+-\d{3}$"
    )
    branch_name: Optional[str] = Field(
        default=None,
        description="Custom branch name (auto-generated if not provided)"
    )
    base_branch: str = Field(
        default="main",
        description="Base branch to create from"
    )
    push_upstream: bool = Field(
        default=False,
        description="Push branch to upstream after creation"
    )

class CommitInput(BaseModel):
    """Input for pm_commit tool"""
    issue_key: str = Field(
        description="Issue key for commit context",
        pattern=r"^[A-Z]+-\d+-\d{3}$"
    )
    message: str = Field(
        description="Commit message (will be formatted with PM trailers)",
        min_length=5
    )
    files: List[str] = Field(
        default_factory=list,
        description="Specific files to commit (all staged if empty)"
    )
    amend: bool = Field(
        default=False,
        description="Amend previous commit"
    )
    log_work: bool = Field(
        default=True,
        description="Automatically log this commit as work activity"
    )

class PushBranchInput(BaseModel):
    """Input for pm_push_branch tool"""
    issue_key: str = Field(
        description="Issue key to push branch for",
        pattern=r"^[A-Z]+-\d+-\d{3}$"
    )
    create_pr: bool = Field(
        default=False,
        description="Create pull request after push"
    )
    pr_title: Optional[str] = Field(
        default=None,
        description="Custom PR title (auto-generated from issue if not provided)"
    )
    pr_body: Optional[str] = Field(
        default=None,
        description="Custom PR body (auto-generated from issue if not provided)"
    )
    reviewers: List[str] = Field(
        default_factory=list,
        description="List of PR reviewers"
    )
    draft: bool = Field(
        default=False,
        description="Create as draft PR"
    )

class StashWorkInput(BaseModel):
    """Input for pm_stash_work tool"""
    issue_key: str = Field(
        description="Issue key for stash context",
        pattern=r"^[A-Z]+-\d+-\d{3}$"
    )
    message: Optional[str] = Field(
        default=None,
        description="Custom stash message"
    )
    include_untracked: bool = Field(
        default=False,
        description="Include untracked files in stash"
    )

# =============== Analytics Models ===============

class ProjectDashboardInput(BaseModel):
    """Input for pm_project_dashboard tool"""
    project_id: Optional[str] = Field(
        default=None,
        description="Project ID (uses default if not specified)"
    )
    timeframe: str = Field(
        default="1w",
        description="Timeframe for metrics (e.g., '1d', '1w', '1m', '3m')",
        pattern=r"^\d+[dwmh]$"
    )
    include_velocity: bool = Field(
        default=True,
        description="Include velocity metrics"
    )
    include_burndown: bool = Field(
        default=True,
        description="Include burndown chart data"
    )
    include_health: bool = Field(
        default=True,
        description="Include project health indicators"
    )

class MyQueueInput(BaseModel):
    """Input for pm_my_queue tool"""
    owner: Optional[str] = Field(
        default=None,
        description="Owner to get queue for (defaults to current agent)"
    )
    include_blocked: bool = Field(
        default=True,
        description="Include blocked issues that might be unblockable"
    )
    sort_by: Literal["priority", "urgency", "age", "dependency"] = Field(
        default="urgency",
        description="Sort order for queue"
    )
    limit: int = Field(
        default=10,
        ge=1,
        le=50,
        description="Maximum items in queue"
    )

class BlockedIssuesInput(BaseModel):
    """Input for pm_blocked_issues tool"""
    project_id: Optional[str] = Field(
        default=None,
        description="Filter by project"
    )
    actionable_only: bool = Field(
        default=True,
        description="Only show blocked issues that can be unblocked now"
    )
    include_stale: bool = Field(
        default=True,
        description="Include issues blocked for > 7 days"
    )

class DependencyGraphInput(BaseModel):
    """Input for pm_dependency_graph tool"""
    issue_key: Optional[str] = Field(
        default=None,
        description="Center graph on specific issue, or show all if not specified"
    )
    project_id: Optional[str] = Field(
        default=None,
        description="Limit to specific project"
    )
    depth: int = Field(
        default=3,
        ge=1,
        le=10,
        description="Maximum depth of dependency traversal"
    )
    format: Literal["json", "ascii", "summary"] = Field(
        default="summary",
        description="Output format for dependency graph"
    )

# =============== Workflow Models ===============

class DailyStandupInput(BaseModel):
    """Input for pm_daily_standup tool"""
    project_id: Optional[str] = Field(
        default=None,
        description="Project ID for standup"
    )
    owner: Optional[str] = Field(
        default=None,
        description="Owner for personalized standup"
    )
    format: Literal["markdown", "text", "structured"] = Field(
        default="markdown",
        description="Output format"
    )
    include_metrics: bool = Field(
        default=True,
        description="Include velocity and progress metrics"
    )

class WeeklyReportInput(BaseModel):
    """Input for pm_weekly_report tool"""
    project_id: Optional[str] = Field(
        default=None,
        description="Project ID for report"
    )
    week_offset: int = Field(
        default=0,
        ge=-4,
        le=0,
        description="Week offset (0=current week, -1=last week)"
    )
    include_velocity: bool = Field(
        default=True,
        description="Include velocity metrics"
    )
    include_risks: bool = Field(
        default=True,
        description="Include risk assessment"
    )
    audience: Literal["technical", "executive", "stakeholder"] = Field(
        default="technical",
        description="Target audience for report tone and detail level"
    )

class CapacityPlanningInput(BaseModel):
    """Input for pm_capacity_planning tool"""
    project_id: Optional[str] = Field(
        default=None,
        description="Project to analyze"
    )
    timeframe: str = Field(
        default="2w",
        description="Planning timeframe",
        pattern=r"^\d+[dw]$"
    )
    include_estimates: bool = Field(
        default=True,
        description="Include effort estimates in capacity calculation"
    )
    team_members: List[str] = Field(
        default_factory=list,
        description="Specific team members to analyze (all if empty)"
    )

class RiskAssessmentInput(BaseModel):
    """Input for pm_risk_assessment tool"""
    project_id: Optional[str] = Field(
        default=None,
        description="Project to assess"
    )
    category: Literal["all", "technical", "timeline", "resource", "external"] = Field(
        default="all",
        description="Risk category to focus on"
    )
    critical_only: bool = Field(
        default=False,
        description="Only show critical/high-impact risks"
    )
    include_mitigation: bool = Field(
        default=True,
        description="Include suggested mitigation strategies"
    )

# =============== Advanced Models ===============

class ExtractRequirementsInput(BaseModel):
    """Input for pm_extract_requirements tool"""
    source: str = Field(
        description="Source content to extract requirements from (markdown, meeting notes, etc.)"
    )
    create_issues: bool = Field(
        default=False,
        description="Automatically create issues from extracted requirements"
    )
    project_id: Optional[str] = Field(
        default=None,
        description="Project ID for created issues"
    )
    default_priority: Literal["P1", "P2", "P3", "P4", "P5"] = Field(
        default="P3",
        description="Default priority for created issues"
    )

class GenerateTestPlanInput(BaseModel):
    """Input for pm_generate_test_plan tool"""
    issue_key: str = Field(
        description="Issue key to generate test plan for",
        pattern=r"^[A-Z]+-\d+-\d{3}$"
    )
    include_performance: bool = Field(
        default=False,
        description="Include performance testing considerations"
    )
    include_security: bool = Field(
        default=False,
        description="Include security testing considerations"
    )
    test_types: List[Literal["unit", "integration", "e2e", "performance", "security", "accessibility"]] = Field(
        default_factory=lambda: ["unit", "integration"],
        description="Types of tests to include in plan"
    )

class SecurityReviewInput(BaseModel):
    """Input for pm_security_review tool"""
    issue_key: str = Field(
        description="Issue key to review for security",
        pattern=r"^[A-Z]+-\d+-\d{3}$"
    )
    compliance: List[Literal["OWASP", "SOC2", "GDPR", "PCI", "HIPAA"]] = Field(
        default_factory=lambda: ["OWASP"],
        description="Compliance frameworks to check against"
    )
    include_checklist: bool = Field(
        default=True,
        description="Include detailed security checklist"
    )

# =============== Utility Models ===============

class WorkflowStatusInput(BaseModel):
    """Input for pm_workflow_status tool"""
    project_id: Optional[str] = Field(
        default=None,
        description="Project to analyze"
    )
    owner: Optional[str] = Field(
        default=None,
        description="Specific owner to analyze"
    )
    detailed: bool = Field(
        default=False,
        description="Include detailed workflow state analysis"
    )

class SuggestNextWorkInput(BaseModel):
    """Input for pm_suggest_next_work tool"""
    project_id: Optional[str] = Field(
        default=None,
        description="Project to suggest work from"
    )
    time_available: Optional[str] = Field(
        default=None,
        description="Available time (e.g., '2h', '1d') for work suggestions"
    )
    skills: List[str] = Field(
        default_factory=list,
        description="Agent skills/preferences for work matching"
    )
    avoid_complex: bool = Field(
        default=False,
        description="Avoid high-complexity issues"
    )


# =============== Error/Result Models ===============

class ErrorDetails(BaseModel):
    """Detailed error information"""
    error_type: str = Field(description="Type of error")
    error_code: Optional[str] = Field(default=None, description="Error code if available")
    details: Optional[Dict[str, Any]] = Field(default=None, description="Additional error details")
    suggestions: Optional[List[str]] = Field(default=None, description="Suggested remediation steps")

# =============== Validation Helpers ===============

def validate_issue_key(key: str) -> bool:
    """Validate issue key format"""
    import re
    return bool(re.match(r"^[A-Z]+-\d+-\d{3}$", key))

def validate_time_format(time_str: str) -> bool:
    """Validate time format"""
    import re
    return bool(re.match(r"^\d+(\.\d+)?[hmd]$", time_str))

def validate_project_id(project_id: str) -> bool:
    """Validate project ID format"""
    return project_id.startswith('pn_') and len(project_id) > 10
```

### mcp/src/server.py
```
#!/usr/bin/env python3
"""
LLM-Native Project Management MCP Server
Production-ready implementation with all fixes applied
"""
import os
import sys
import asyncio
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional

# Add parent directory to path for imports
sys.path.insert(0, str(Path(__file__).parent))

try:
    from mcp.server.fastmcp import FastMCP
except ImportError:
    print("❌ Error: MCP library not installed. Run 'pip install mcp' first.")
    sys.exit(1)

from config import Config
from database import PMDatabase, DatabaseSession
from models import *
from utils import *
from git_integration import git_status, git_current_branch, git_push_current

# Initialize MCP server
mcp = FastMCP("pm-server")

# Ensure database is initialized
PMDatabase.initialize()

# =============== Helper Functions ===============

def _auto_project_id() -> Optional[str]:
    """Pick project by CWD if PM_DEFAULT_PROJECT_ID not set."""
    env = Config.get_default_project_id()
    if env:
        return env
    try:
        cwd = Path(os.getcwd()).resolve()
        for p in PMDatabase.get_all_projects():
            try:
                p_path = Path(p.absolute_path).resolve()
                # exact repo or subdir
                if cwd == p_path or str(cwd).startswith(str(p_path) + os.sep):
                    return p.project_id
            except Exception:
                continue
    except Exception:
        pass
    # Fallback: first project if any
    projects = PMDatabase.get_all_projects()
    return projects[0].project_id if projects else None

def _require_project_id(explicit: Optional[str]) -> Optional[str]:
    return explicit or _auto_project_id()

def get_default_project_id() -> Optional[str]:
    """Get default project ID from config or first available"""
    if Config.DEFAULT_PROJECT_ID:
        return Config.DEFAULT_PROJECT_ID

    try:
        with DatabaseSession():
            projects = PMDatabase.get_all_projects()
            if projects:
                # projects is now a list of models, not dicts
                return projects[0].project_id
    except Exception:
        pass
    return None

# Use standardized response functions from utils
# Compatibility shim for migration period
def standard_response(success: bool, message: str, data: Optional[Dict[str, Any]] = None,
                     hints: Optional[List[str]] = None) -> Dict[str, Any]:
    """Compatibility shim - use ok() and err() for new code"""
    if success:
        return ok(message, data, hints)
    else:
        return err(message, data, hints)

# =============== Discovery Tools ===============

@mcp.tool()
def pm_docs(input: PMDocsInput) -> Dict[str, Any]:
    """
    Get comprehensive PM system documentation and workflow guidance.
    This tool provides the LLM with understanding of available commands,
    workflows, and best practices for project management.
    """
    docs = {
        "overview": """# LLM-Native Project Management System

This PM system is designed for LLM agents as first-class citizens, providing:
- Rich context and documentation in every issue
- Git integration with automatic branch and commit management
- Comprehensive work tracking and analytics
- Workflow automation and intelligent planning

## Core Concepts
- **Issues**: Rich, documented work items with LLM-generated specs
- **Projects**: Collections of issues with modules and metadata
- **Work Logs**: Detailed activity tracking with artifacts
- **Git Integration**: Automatic branch creation and commit formatting

## Available Tool Categories
1. **Discovery**: pm_docs, pm_status, pm_list_issues, pm_get_issue, pm_search_issues
2. **Planning**: pm_create_issue, pm_update_issue, pm_estimate, pm_refine_issue
3. **Execution**: pm_start_work, pm_log_work, pm_update_status, pm_create_task
4. **Git**: pm_git_status, pm_create_branch, pm_commit, pm_push_branch
5. **Analytics**: pm_project_dashboard, pm_my_queue, pm_blocked_issues
6. **Workflow**: pm_daily_standup, pm_weekly_report, pm_capacity_planning""",

        "commands": """# PM Command Reference

## Discovery Commands
- `pm_docs`: Get documentation (this command)
- `pm_status`: Project status overview with metrics
- `pm_list_issues`: List and filter issues with sorting
- `pm_get_issue`: Get detailed issue with context
- `pm_list_projects`: List all available projects
- `pm_search_issues`: Full-text search across all content

## Planning Commands
- `pm_create_issue`: Create comprehensive issue with rich specs
- `pm_update_issue`: Update issue details and content
- `pm_estimate`: Add effort and complexity estimates with reasoning
- `pm_refine_issue`: Iteratively refine requirements and approach

## Execution Commands
- `pm_start_work`: Begin work on issue (status + optional branch)
- `pm_log_work`: Log development activity with artifacts
- `pm_update_status`: Change issue status with workflow validation
- `pm_create_task`: Break issue into manageable tasks

## Git Integration
- `pm_git_status`: Enhanced git status with issue context
- `pm_create_branch`: Create feature branch with conventions
- `pm_commit`: Commit with PM trailers and formatting
- `pm_push_branch`: Push and optionally create PR

## Analytics & Reporting
- `pm_project_dashboard`: Comprehensive project health metrics
- `pm_my_queue`: Personal work queue with intelligent prioritization
- `pm_blocked_issues`: Find and analyze blocked work
- `pm_daily_standup`: Generate daily standup report
- `pm_weekly_report`: Weekly progress and velocity report""",

        "workflow": """# Typical LLM Agent Workflow

## 1. Fresh Session Startup
```
pm_docs                    # Understand the system capabilities
pm_status                  # Get project health overview
pm_my_queue               # Get prioritized work queue
pm_blocked_issues         # Check for unblocking opportunities
```

## 2. Creating New Feature
```
pm_create_issue --type feature --title "Add user authentication"
  --description "Comprehensive technical specification..."
  --priority P2 --module backend

pm_estimate --effort "3-5 days" --complexity High
  --reasoning "JWT implementation + database changes + testing"

pm_refine_issue --aspect technical
  --suggestions "Consider OAuth integration for future"
```

## 3. Starting Implementation
```
pm_start_work --issue-key PROJ-001    # Status → in_progress + branch
pm_git_status                         # Verify git state
pm_create_branch                      # Create if not auto-created
```

## 4. Development Loop
```
pm_log_work --activity code --summary "Implemented JWT middleware"
  --artifacts '[{"type":"file","path":"src/auth.py"}]'
  --time-spent "2h"

pm_commit --message "feat: add JWT authentication middleware"
# Auto-formatted: [pm PROJ-001] feat: add JWT middleware\n\nPM: PROJ-001

pm_create_task --title "Add integration tests"
  --checklist '["Write auth tests","Test token validation"]'
```

## 5. Completion
```
pm_update_status --status review
  --notes "Implementation complete, ready for security review"

pm_push_branch --create-pr
  --reviewers '["security-team","backend-team"]'

pm_log_work --activity review
  --summary "Created PR and requested reviews"
```""",

        "troubleshooting": """# Troubleshooting Guide

## Common Issues

### Database Connection
- Ensure `PM_DATABASE_PATH` points to valid SQLite file
- Run Jira-lite migration if database doesn't exist
- Check file permissions on database file

### Git Operations
- Ensure you're in a valid git repository
- Check git identity is configured
- Verify remote branches exist before pulling

### Issue Creation
- Ensure project exists and is registered
- Use descriptive titles and detailed descriptions
- Include acceptance criteria for better tracking

## Environment Variables
- `PM_DATABASE_PATH`: Path to SQLite database (required)
- `PM_DEFAULT_PROJECT_ID`: Default project to use
- `PM_DEFAULT_OWNER`: Default issue owner
- `GIT_USER_NAME`: Git commit author name
- `GIT_USER_EMAIL`: Git commit author email

## Commands for Debug
- `pm_status --verbose`: Detailed project health
- `pm_list_projects`: See all available projects
- `pm_git_status`: Check git repository state
- `pm_blocked_issues`: Find systematic blockers"""
    }

    section = input.section or "overview"
    content = docs.get(section, docs["overview"])

    return ok(f"Documentation: {section}", {
        "content": content,
        "section": section,
        "available_sections": list(docs.keys())
    }, hints=["Use --section parameter to get specific documentation sections"])

@mcp.tool()
@strict_project_scope
def pm_status(input: PMStatusInput) -> Dict[str, Any]:
    """
    Get comprehensive project status including issue counts, velocity metrics,
    and current work distribution. Essential for understanding project health.
    """
    try:
        with DatabaseSession():
            pid = _require_project_id(input.project_id)
            if not pid:
                return err("No project found. Initialize one with pm_init_project()", {})
            project = PMDatabase.get_project(pid)
            if not project:
                return err(f"Project not found: {pid}", {})

            # Convert project model to dict
            proj_dict = PMDatabase._project_to_dict(project)

            # Get project metrics
            metrics = PMDatabase.project_metrics(project)

            data = {
                "project": proj_dict,
                "metrics": metrics,
            }
            return ok("Project status", data)
    except Exception as e:
        return err(f"Failed to get project status: {type(e).__name__}", {"trace": str(e)})

@mcp.tool()
@strict_project_scope
def pm_list_issues(input: ListIssuesInput) -> Dict[str, Any]:
    """
    List and filter project issues with comprehensive details.
    Returns structured issue data suitable for analysis and planning.
    """
    try:
        with DatabaseSession():
            pid = _require_project_id(input.project_id)
            if not pid:
                return err("No project found. Initialize one with pm_init_project()", {})
            issues = PMDatabase.find_issues(pid,
                                            status=input.status, priority=input.priority,
                                            module=input.module, q=None, query=None)
            return ok(f"Found {len(issues)} issues",
                      {"issues": [i.to_rich_dict() for i in issues], "count": len(issues)})
    except Exception as e:
        return err(f"Failed to list issues: {type(e).__name__}", {"trace": str(e)})

@mcp.tool()
@strict_project_scope
def pm_get_issue(input: GetIssueInput) -> Dict[str, Any]:
    """
    Get comprehensive issue details including specifications, tasks, and work history.
    Essential for understanding issue context before starting work.
    FIXED: Uses Peewee models instead of raw SQL queries.
    """
    try:
        with DatabaseSession():
            if input.include_tasks or input.include_worklogs:
                # Get issue with all relations using Peewee models
                issue_data = PMDatabase.get_issue_with_relations(input.issue_key)
                if not issue_data:
                    return standard_response(
                        success=False,
                        message=f"Issue {input.issue_key} not found",
                        hints=["Use pm_search_issues to find issues", "Check issue key format"]
                    )

                result_data = {
                    "issue": issue_data['issue']
                }

                if input.include_tasks:
                    result_data["tasks"] = issue_data['tasks']

                if input.include_worklogs:
                    result_data["worklogs"] = issue_data['worklogs']

                # Add project info
                result_data["project"] = issue_data['project']

            else:
                # Get just the issue - scoped to current project
                issue = PMDatabase.get_issue_scoped(input.project_id, input.issue_key)
                if issue is None:
                    return standard_response(
                        success=False,
                        message=f"Issue {input.issue_key} not found in current project"
                    )
                result_data = {"issue": PMDatabase._issue_to_dict(issue)}

            # Add dependency analysis if requested
            if input.include_dependencies:
                all_issues = PMDatabase.get_issues(project_id=result_data['issue']['project_id'], limit=1000)
                deps = analyze_dependencies(result_data['issue'], all_issues)
                result_data["dependencies"] = deps

            # Generate contextual next steps
            issue = result_data['issue']
            hints = []
            if issue['status'] == 'proposed':
                hints.extend([
                    f"pm_estimate --issue-key {issue['key']} to add effort estimates",
                    f"pm_refine_issue --issue-key {issue['key']} to refine requirements",
                    f"pm_start_work --issue-key {issue['key']} to begin implementation"
                ])
            elif issue['status'] == 'in_progress':
                hints.extend([
                    f"pm_log_work --issue-key {issue['key']} to track current activity",
                    f"pm_create_task --issue-key {issue['key']} to break down work",
                    f"pm_commit --issue-key {issue['key']} to save changes"
                ])
            elif issue['status'] == 'review':
                hints.extend([
                    f"pm_push_branch --issue-key {issue['key']} --create-pr to create pull request",
                    f"pm_update_status --issue-key {issue['key']} --status done when approved"
                ])

            return standard_response(
                success=True,
                message=f"Issue details for {input.issue_key}",
                data=result_data,
                hints=hints
            )

    except ScopeError as se:
        return err(str(se))
    except Exception as e:
        return standard_response(
            success=False,
            message=f"Failed to get issue: {type(e).__name__}",
            hints=["Check database connectivity", "Verify issue key format"]
        )

@mcp.tool()
def pm_search_issues(input: SearchIssuesInput) -> Dict[str, Any]:
    """
    Full-text search across all issue content.
    Searches titles, descriptions, and all rich content fields.
    """
    try:
        with DatabaseSession():
            issues = PMDatabase.search_issues(
                query_text=input.query,
                project_id=input.project_id,
                limit=input.limit
            )

            # If not including content, strip heavy fields for performance
            if not input.include_content:
                for issue in issues:
                    issue.pop('description', None)
                    issue.pop('technical_approach', None)

            return standard_response(
                success=True,
                message=f"Found {len(issues)} issues matching '{input.query}'",
                data={
                    "query": input.query,
                    "project_id": input.project_id,
                    "results": issues,
                    "total_matches": len(issues),
                    "include_content": input.include_content
                },
                hints=[
                    f"Use pm_get_issue --issue-key {issues[0]['key']} for full details" if issues else "Try broader search terms",
                    "Use --include-content true to see full descriptions in results"
                ]
            )

    except Exception as e:
        return standard_response(
            success=False,
            message=f"Search failed: {type(e).__name__}",
            hints=["Check database connectivity", "Try simpler search terms"]
        )

@mcp.tool()
def pm_list_projects() -> Dict[str, Any]:
    """
    List all available projects in the system.
    Shows project metadata and basic statistics.
    """
    try:
        with DatabaseSession():
            projects = PMDatabase.get_all_projects()
            # Convert models to dicts
            data = {"projects": [PMDatabase._project_to_dict(p) for p in projects],
                    "count": len(projects)}
        return ok(f"Found {len(projects)} projects", data)
    except Exception as e:
        return err(f"Failed to list projects: {type(e).__name__}", {"trace": str(e)})

# =============== Planning Tools ===============

@mcp.tool()
@strict_project_scope
def pm_create_issue(input: CreateIssueInput) -> Dict[str, Any]:
    """
    Create a comprehensive issue with rich LLM-generated documentation.
    This is the primary tool for capturing work with full context and specifications.
    """
    try:
        with DatabaseSession():
            # ensure project_id is set / auto-scoped
            if not input.project_id:
                object.__setattr__(input, "project_id", _require_project_id(None))
            issue = PMDatabase.create_issue(input)
            return ok("Issue created", {"issue": issue.to_rich_dict()},
                      hints=[f"Start work: pm_start_work --issue-key {issue.key}"])
    except Exception as e:
        return err(f"Failed to create issue: {type(e).__name__}", {"trace": str(e)})

@mcp.tool()
@strict_project_scope
def pm_start_work(input: StartWorkInput) -> Dict[str, Any]:
    """
    Start work on an issue - updates status, optionally creates branch.
    This is the primary entry point for beginning implementation.
    """
    try:
        with DatabaseSession():
            # Get issue scoped to current project
            issue = PMDatabase.get_issue_scoped(input.project_id, input.issue_key)
            if issue is None:
                return standard_response(
                    success=False,
                    message=f"Issue {input.issue_key} not found in current project"
                )
            issue_dict = PMDatabase._issue_to_dict(issue)

            # Validate dependencies if requested
            if input.validate_dependencies:
                all_issues = PMDatabase.get_issues(project_id=issue_dict['project_id'], limit=1000)
                deps = analyze_dependencies(issue_dict, all_issues)
                if not deps['ready_to_work']:
                    pending = [d['key'] for d in deps['depends_on'] if not d['ready']]
                    return standard_response(
                        success=False,
                        message=f"Cannot start work - dependencies not completed: {', '.join(pending)}",
                        hints=[f"Complete dependencies first: {', '.join(pending)}"]
                    )

            # Update status to in_progress
            update_data = issue_dict.copy()
            old_status = issue_dict['status']
            update_data['status'] = 'in_progress'
            updated_issue = PMDatabase.create_or_update_issue(update_data)

            # Log work start
            PMDatabase.add_worklog({
                'issue_key': input.issue_key,
                'agent': Config.DEFAULT_OWNER,
                'activity': 'planning',
                'summary': f"Started work on {input.issue_key}: {issue_dict['title']}",
                'context': {
                    'previous_status': old_status,
                    'notes': input.notes or "Beginning implementation"
                }
            })

            result_data = {
                "issue": updated_issue,
                "status_changed": f"{old_status} → in_progress"
            }

            hints = [
                f"pm_log_work --issue-key {input.issue_key} to track progress",
                f"pm_create_task --issue-key {input.issue_key} to break down work"
            ]

            # Handle branch creation if requested
            if input.create_branch:
                project = PMDatabase.get_project(issue_dict['project_id'])
                if project:
                    try:
                        branch_name = issue_dict.get('branch_hint') or generate_branch_name(
                            input.issue_key, issue_dict['type'], issue_dict['title']
                        )

                        # Get project dict for path access
                        if hasattr(project, 'absolute_path'):
                            project_path = Path(project.absolute_path)
                        else:
                            project_dict = PMDatabase._project_to_dict(project) if project else {}
                            project_path = Path(project_dict['absolute_path']) if project_dict else Path.cwd()

                        # Ensure git setup
                        if not asyncio.run(ensure_project_git_setup(project_path)):
                            result_data['branch_warning'] = 'Git setup incomplete - manual branch creation recommended'
                        else:
                            git_result = run_git_command_sync(['checkout', '-b', branch_name], cwd=project_path)
                            if git_result['success']:
                                result_data['branch_created'] = branch_name
                                sanitized = sanitize_git_output(git_result['output'], git_result.get('error', ''))
                                result_data['git_output'] = sanitized['output']
                                hints.append(f"Branch '{branch_name}' created and checked out")
                            else:
                                result_data['branch_error'] = git_result['error']
                                hints.append("Branch creation failed - create manually if needed")
                    except Exception:
                        result_data['branch_error'] = 'Branch creation failed'

            return standard_response(
                success=True,
                message=f"Started work on {input.issue_key}",
                data=result_data,
                hints=hints
            )

    except ScopeError as se:
        return err(str(se))
    except Exception as e:
        return standard_response(
            success=False,
            message=f"Failed to start work: {type(e).__name__}",
            hints=["Check issue exists", "Verify issue is in startable state"]
        )

@mcp.tool()
@strict_project_scope
def pm_log_work(input: LogWorkInput) -> Dict[str, Any]:
    """
    Log development activity with artifacts and context.
    Essential for tracking progress and building project knowledge.
    """
    try:
        with DatabaseSession():
            # Validate issue belongs to current project - using strict scope
            issue = PMDatabase.get_issue_scoped(input.project_id, input.issue_key)
            if issue is None:
                return err("Issue not found in current project scope")
            issue_dict = PMDatabase._issue_to_dict(issue)

            # Build work log data
            context_data = {}
            if input.time_spent:
                context_data['time_spent'] = input.time_spent
                context_data['hours_logged'] = parse_duration(input.time_spent)
            if input.blockers:
                context_data['blockers'] = input.blockers
            if input.decisions:
                context_data['decisions'] = input.decisions

            worklog_data = {
                'issue_key': input.issue_key,
                'agent': Config.DEFAULT_OWNER,
                'activity': input.activity,
                'summary': input.summary,
                'artifacts': input.artifacts,
                'context': context_data
            }

            if input.task_id:
                worklog_data['task_id'] = input.task_id

            worklog = PMDatabase.add_worklog(worklog_data)

            # Calculate time for response
            hours_spent = parse_duration(input.time_spent) if input.time_spent else 0

            return standard_response(
                success=True,
                message=f"Logged {input.activity} work on {input.issue_key}",
                data={
                    "worklog": worklog,
                    "time_logged": input.time_spent,
                    "hours_logged": hours_spent,
                    "artifacts_count": len(input.artifacts)
                },
                hints=[
                    f"pm_commit --issue-key {input.issue_key} to save code changes",
                    f"pm_update_status --issue-key {input.issue_key} to change status when ready"
                ]
            )

    except Exception as e:
        return standard_response(
            success=False,
            message=f"Failed to log work: {type(e).__name__}",
            hints=["Check issue exists", "Verify time format (e.g., '2h', '30m')"]
        )

# =============== Git Integration Tools ===============

@mcp.tool()
@strict_project_scope
def pm_create_branch(input: CreateBranchInput) -> Dict[str, Any]:
    """
    Create a git branch for an issue following naming conventions.
    Automatically configures branch tracking and updates issue metadata.
    FIXED: Proper error handling and security.
    """
    try:
        with DatabaseSession():
            issue = PMDatabase.get_issue(input.issue_key)
            if not issue:
                return standard_response(
                    success=False,
                    message=f"Issue {input.issue_key} not found"
                )
            issue_dict = PMDatabase._issue_to_dict(issue)

            project = PMDatabase.get_project(issue_dict['project_id'])
            if not project:
                return standard_response(
                    success=False,
                    message=f"Project {issue_dict['project_id']} not found"
                )

            # Rate limiting check
            if not git_rate_limiter.can_proceed():
                return standard_response(
                    success=False,
                    message="Rate limit exceeded for git operations",
                    hints=["Wait a moment before retrying git operations"]
                )

            # Generate or validate branch name
            branch_name = input.branch_name or issue_dict.get('branch_hint') or generate_branch_name(
                input.issue_key, issue_dict['type'], issue_dict['title']
            )

            if not validate_branch_name(branch_name):
                return standard_response(
                    success=False,
                    message=f"Invalid branch name: {branch_name}",
                    hints=["Use alphanumeric characters and hyphens only"]
                )

            # Get project dict for path access
            if hasattr(project, 'absolute_path'):
                project_path = Path(project.absolute_path)
            else:
                project_dict = PMDatabase._project_to_dict(project) if project else {}
                project_path = Path(project_dict['absolute_path']) if project_dict else Path.cwd()

            # Ensure git setup
            setup_success = asyncio.run(ensure_project_git_setup(project_path))
            if not setup_success:
                return standard_response(
                    success=False,
                    message="Git setup failed - ensure repository is properly initialized",
                    hints=["Check if directory is a git repository", "Verify git is installed"]
                )

            # Checkout base branch safely
            git_result = run_git_command_sync(['checkout', input.base_branch], cwd=project_path)
            if not git_result['success']:
                return standard_response(
                    success=False,
                    message=f"Failed to checkout base branch {input.base_branch}",
                    data={"git_error": git_result['error']},
                    hints=[f"Ensure branch '{input.base_branch}' exists"]
                )

            # Pull latest changes (handle gracefully if no remote)
            pull_result = run_git_command_sync(['pull'], cwd=project_path)
            # Don't fail on pull errors - might be offline or no remote

            # Create new branch
            git_result = run_git_command_sync(['checkout', '-b', branch_name], cwd=project_path)

            if git_result['success']:
                # Update issue with branch info
                update_data = issue_dict.copy()
                update_data['branch_hint'] = branch_name
                PMDatabase.create_or_update_issue(update_data)

                # Log branch creation
                PMDatabase.add_worklog({
                    'issue_key': input.issue_key,
                    'agent': Config.DEFAULT_OWNER,
                    'activity': 'code',
                    'summary': f"Created branch: {branch_name}",
                    'artifacts': [
                        {
                            'type': 'branch',
                            'name': branch_name,
                            'base': input.base_branch
                        }
                    ]
                })

                sanitized = sanitize_git_output(git_result['output'], git_result.get('error', ''))

                return standard_response(
                    success=True,
                    message=f"Created and checked out branch: {branch_name}",
                    data={
                        "branch": branch_name,
                        "base_branch": input.base_branch,
                        "git_output": sanitized['output']
                    },
                    hints=[
                        f"pm_log_work --issue-key {input.issue_key} to start tracking work",
                        f"pm_commit --issue-key {input.issue_key} to save changes"
                    ]
                )
            else:
                sanitized = sanitize_git_output(git_result.get('output', ''), git_result.get('error', ''))
                return standard_response(
                    success=False,
                    message="Failed to create branch",
                    data={"git_error": sanitized['error']},
                    hints=["Check if branch already exists", "Ensure working directory is clean"]
                )

    except Exception as e:
        return standard_response(
            success=False,
            message=f"Branch creation failed: {type(e).__name__}",
            hints=["Check git repository status", "Verify project path exists"]
        )

@mcp.tool()
def pm_commit(input: CommitInput) -> Dict[str, Any]:
    """
    Create a git commit with PM trailers and issue context.
    Automatically formats commit messages with conventional commit style.
    FIXED: Proper regex handling and async safety.
    """
    try:
        with DatabaseSession():
            issue = PMDatabase.get_issue(input.issue_key)
            if not issue:
                return standard_response(
                    success=False,
                    message=f"Issue {input.issue_key} not found"
                )
            issue_dict = PMDatabase._issue_to_dict(issue)

            project = PMDatabase.get_project(issue_dict['project_id'])
            if not project:
                return standard_response(
                    success=False,
                    message=f"Project {issue_dict['project_id']} not found"
                )

            # Rate limiting
            if not git_rate_limiter.can_proceed():
                return standard_response(
                    success=False,
                    message="Rate limit exceeded for git operations"
                )

            # Get project dict for path access
            if hasattr(project, 'absolute_path'):
                project_path = Path(project.absolute_path)
            else:
                project_dict = PMDatabase._project_to_dict(project) if project else {}
                project_path = Path(project_dict['absolute_path']) if project_dict else Path.cwd()

            # Ensure git identity is set
            setup_success = asyncio.run(ensure_project_git_setup(project_path))
            if not setup_success:
                return standard_response(
                    success=False,
                    message="Git identity setup failed"
                )

            # Format commit message with FIXED regex
            commit_message = format_commit_message(input.issue_key, input.message)

            # Stage files if specified
            if input.files:
                for file in input.files:
                    git_result = run_git_command_sync(['add', file], cwd=project_path)
                    if not git_result['success']:
                        return standard_response(
                            success=False,
                            message=f"Failed to stage file: {file}",
                            data={"git_error": git_result['error']}
                        )
            else:
                # Stage all changes
                git_result = run_git_command_sync(['add', '-A'], cwd=project_path)

            # Create commit
            commit_args = ['commit', '-m', commit_message]
            if input.amend:
                commit_args.append('--amend')

            git_result = run_git_command_sync(commit_args, cwd=project_path)

            if git_result['success']:
                # Get commit SHA
                sha_result = run_git_command_sync(['rev-parse', 'HEAD'], cwd=project_path)
                commit_sha = sha_result['output'][:7] if sha_result['success'] else 'unknown'

                # Log commit as work activity if requested
                if input.log_work:
                    PMDatabase.add_worklog({
                        'issue_key': input.issue_key,
                        'agent': Config.DEFAULT_OWNER,
                        'activity': 'code',
                        'summary': f"Committed: {input.message}",
                        'artifacts': [
                            {
                                'type': 'commit',
                                'sha': commit_sha,
                                'message': commit_message,
                                'files': input.files or []
                            }
                        ]
                    })

                sanitized = sanitize_git_output(git_result['output'], git_result.get('error', ''))

                return standard_response(
                    success=True,
                    message="Commit created successfully",
                    data={
                        "commit_sha": commit_sha,
                        "commit_message": commit_message,
                        "git_output": sanitized['output']
                    },
                    hints=[
                        f"pm_push_branch --issue-key {input.issue_key} to push changes",
                        f"pm_log_work --issue-key {input.issue_key} to continue tracking work"
                    ]
                )
            else:
                sanitized = sanitize_git_output(git_result.get('output', ''), git_result.get('error', ''))
                return standard_response(
                    success=False,
                    message="Failed to create commit",
                    data={"git_error": sanitized['error']},
                    hints=["Check if there are changes to commit", "Verify git repository state"]
                )

    except Exception as e:
        return standard_response(
            success=False,
            message=f"Commit failed: {type(e).__name__}",
            hints=["Check git repository status", "Verify working directory"]
        )

# =============== Analytics Tools ===============

@mcp.tool()
@strict_project_scope
def pm_my_queue(input: MyQueueInput) -> Dict[str, Any]:
    """
    Get personalized work queue with intelligent prioritization.
    Helps agents focus on the most important work.
    """
    owner = input.owner or Config.DEFAULT_OWNER

    try:
        with DatabaseSession():
            # Get assigned issues
            my_issues = PMDatabase.get_issues(owner=owner, limit=100)

            # Filter to actionable statuses
            actionable = [
                i for i in my_issues
                if i['status'] in ['proposed', 'in_progress', 'review']
            ]

            # Add blocked issues that might be unblockable
            if input.include_blocked:
                blocked_issues = PMDatabase.get_blocked_issues()
                all_issues = PMDatabase.get_issues(limit=1000)

                for blocked in blocked_issues:
                    deps = analyze_dependencies(blocked, all_issues)
                    if deps['ready_to_work']:
                        blocked['unblockable'] = True
                        actionable.append(blocked)

            # Sort based on criteria
            if input.sort_by == 'priority':
                priority_order = {'P1': 1, 'P2': 2, 'P3': 3, 'P4': 4, 'P5': 5}
                actionable.sort(key=lambda i: priority_order.get(i['priority'], 6))
            elif input.sort_by == 'urgency':
                actionable.sort(key=calculate_urgency_score, reverse=True)
            elif input.sort_by == 'dependency':
                # Sort by blocking others first, then by dependency count
                all_issues = PMDatabase.get_issues(limit=1000)
                def dep_score(issue):
                    deps = analyze_dependencies(issue, all_issues)
                    return (deps['blocking_count'] * 10) - deps['dependency_count']
                actionable.sort(key=dep_score, reverse=True)
            else:  # age
                actionable.sort(key=lambda i: i['created_utc'])

            # Format queue with recommendations
            queue = []
            for issue in actionable[:input.limit]:
                age_days = (datetime.utcnow() - datetime.fromisoformat(issue['created_utc'].rstrip('Z'))).days

                item = {
                    "key": issue['key'],
                    "title": issue['title'],
                    "type": issue['type'],
                    "status": issue['status'],
                    "priority": issue['priority'],
                    "age_days": age_days,
                    "urgency_score": calculate_urgency_score(issue)
                }

                # Add actionable recommendations
                if issue['status'] == 'proposed':
                    item['recommended_action'] = "pm_start_work"
                elif issue['status'] == 'in_progress':
                    item['recommended_action'] = "pm_log_work or pm_commit"
                elif issue['status'] == 'review':
                    item['recommended_action'] = "pm_push_branch --create-pr"
                elif issue['status'] == 'blocked' and issue.get('unblockable'):
                    item['recommended_action'] = "pm_update_status --status in_progress"

                queue.append(item)

            hints = []
            if queue:
                top_item = queue[0]
                hints.append(f"Focus on {top_item['key']}: {top_item['title']} ({top_item['recommended_action']})")
            else:
                hints.append("Queue is empty - consider pm_create_issue to add new work")

            if len(actionable) > input.limit:
                hints.append(f"Showing top {input.limit} of {len(actionable)} actionable items")

            return standard_response(
                success=True,
                message=f"Work queue for {owner}",
                data={
                    "owner": owner,
                    "queue": queue,
                    "total_assigned": len(my_issues),
                    "actionable_count": len(actionable),
                    "sort_method": input.sort_by
                },
                hints=hints
            )

    except Exception as e:
        return standard_response(
            success=False,
            message=f"Failed to get work queue: {type(e).__name__}",
            hints=["Check database connectivity"]
        )

@mcp.tool()
def pm_blocked_issues(input: BlockedIssuesInput) -> Dict[str, Any]:
    """
    Find and analyze blocked issues with unblocking recommendations.
    Helps identify systematic blockers and resolution paths.
    """
    try:
        with DatabaseSession():
            blocked = PMDatabase.get_blocked_issues(project_id=input.project_id)

            if not blocked:
                return standard_response(
                    success=True,
                    message="No blocked issues found",
                    data={"blocked_issues": [], "total_blocked": 0},
                    hints=["Great! No blockers to resolve"]
                )

            all_issues = PMDatabase.get_issues(project_id=input.project_id, limit=1000)
            result_issues = []

            for issue in blocked:
                blocked_info = {
                    'issue': issue,
                    'can_unblock': False,
                    'unblock_actions': [],
                    'days_blocked': 0
                }

                # Analyze dependencies
                deps = analyze_dependencies(issue, all_issues)
                blocked_info['can_unblock'] = deps['ready_to_work']

                if deps['ready_to_work']:
                    blocked_info['unblock_actions'].append('All dependencies completed - ready to resume')
                else:
                    pending = [d['key'] for d in deps['depends_on'] if not d['ready']]
                    blocked_info['unblock_actions'].append(f"Waiting for: {', '.join(pending)}")

                # Check how long it's been blocked
                updated = datetime.fromisoformat(issue['updated_utc'].rstrip('Z'))
                days_blocked = (datetime.utcnow() - updated).days
                blocked_info['days_blocked'] = days_blocked

                if input.include_stale and days_blocked > 7:
                    blocked_info['unblock_actions'].append(f'Blocked for {days_blocked} days - review if still valid')
                    blocked_info['stale'] = True

                # Include based on filters
                if input.actionable_only:
                    if blocked_info['can_unblock'] or (input.include_stale and days_blocked > 7):
                        result_issues.append(blocked_info)
                else:
                    result_issues.append(blocked_info)

            # Sort by actionability and age
            result_issues.sort(key=lambda x: (x['can_unblock'], -x['days_blocked']), reverse=True)

            recommendations = []
            for item in result_issues[:5]:
                if item['can_unblock']:
                    recommendations.append(f"Unblock {item['issue']['key']}: {item['issue']['title']}")

            hints = []
            actionable_count = len([i for i in result_issues if i['can_unblock']])
            if actionable_count > 0:
                hints.append(f"{actionable_count} issues can be unblocked now")
            if len(result_issues) > actionable_count:
                hints.append(f"{len(result_issues) - actionable_count} issues still waiting on dependencies")

            return standard_response(
                success=True,
                message=f"Found {len(result_issues)} blocked issues",
                data={
                    "blocked_issues": result_issues,
                    "total_blocked": len(blocked),
                    "actionable": actionable_count,
                    "recommendations": recommendations
                },
                hints=hints
            )

    except Exception as e:
        return standard_response(
            success=False,
            message=f"Failed to analyze blocked issues: {type(e).__name__}",
            hints=["Check database connectivity"]
        )

# =============== Workflow Tools ===============

@mcp.tool()
@strict_project_scope
def pm_daily_standup(input: DailyStandupInput) -> Dict[str, Any]:
    """
    Generate daily standup report with yesterday's work, today's plan, and blockers.
    Perfect for automated status updates and team synchronization.
    """
    # Project scoping handled by decorator
    owner = input.owner or Config.DEFAULT_OWNER

    try:
        with DatabaseSession():
            # Get yesterday's work logs
            yesterday = datetime.utcnow() - timedelta(days=1)
            yesterday_work = PMDatabase.get_recent_worklogs(
                project_id=input.project_id,
                limit=50
            )

            # Filter to yesterday and specific owner
            yesterday_work = [
                w for w in yesterday_work
                if (datetime.fromisoformat(w['timestamp_utc'].rstrip('Z')).date() == yesterday.date() and
                    w.get('agent') == owner)
            ]

            # Get today's planned work (in_progress issues)
            today_issues = PMDatabase.get_issues(
                project_id=input.project_id,
                owner=owner,
                status='in_progress',
                limit=10
            )

            # Get blockers
            blocked_issues = PMDatabase.get_blocked_issues(project_id=input.project_id)

            # Format based on requested format
            if input.format == 'markdown':
                content = format_standup_report(yesterday_work, today_issues, blocked_issues)
            elif input.format == 'structured':
                content = {
                    "date": datetime.now().strftime('%Y-%m-%d'),
                    "yesterday": [
                        {
                            "issue": w['issue_key'],
                            "activity": w.get('activity', 'unknown'),
                            "summary": w['summary']
                        } for w in yesterday_work
                    ],
                    "today": [
                        {
                            "issue": i['key'],
                            "title": i['title'],
                            "priority": i['priority']
                        } for i in today_issues
                    ],
                    "blockers": [
                        {
                            "issue": b['key'],
                            "title": b['title'],
                            "blocked_since": b['updated_utc']
                        } for b in blocked_issues
                    ]
                }
            else:  # text
                lines = [f"Daily Standup - {datetime.now().strftime('%Y-%m-%d')}"]
                lines.append(f"\nOwner: {owner}")
                lines.append("\nYesterday:")
                for w in yesterday_work:
                    lines.append(f"- {w['issue_key']}: {w['summary']}")
                if not yesterday_work:
                    lines.append("- No logged work yesterday")

                lines.append("\nToday:")
                for i in today_issues:
                    lines.append(f"- {i['key']}: {i['title']} ({i['priority']})")
                if not today_issues:
                    lines.append("- No active issues")

                lines.append("\nBlockers:")
                for b in blocked_issues[:3]:  # Limit to prevent spam
                    lines.append(f"- {b['key']}: {b['title']}")
                if not blocked_issues:
                    lines.append("- No blockers")

                content = "\n".join(lines)

            hints = []
            if not yesterday_work:
                hints.append("No work logged yesterday - consider pm_log_work for better tracking")
            if not today_issues:
                hints.append("No active work - use pm_my_queue to find work or pm_create_issue to add new work")
            if blocked_issues:
                hints.append(f"pm_blocked_issues to analyze {len(blocked_issues)} blocked items")

            return standard_response(
                success=True,
                message=f"Daily standup for {owner}",
                data={
                    "report": content,
                    "format": input.format,
                    "stats": {
                        "yesterday_items": len(yesterday_work),
                        "today_items": len(today_issues),
                        "blockers": len(blocked_issues)
                    },
                    "project": input.project_id,
                    "owner": owner
                },
                hints=hints
            )

    except Exception as e:
        return standard_response(
            success=False,
            message=f"Failed to generate standup: {type(e).__name__}",
            hints=["Check database connectivity", "Verify project exists"]
        )

# =============== Main Entry Point ===============

def main():
    """Main entry point for the MCP server with proper configuration handling"""
    import argparse

    parser = argparse.ArgumentParser(description="PM MCP Server - LLM-Native Project Management")
    parser.add_argument("--transport", choices=["stdio", "http", "sse"],
                       default=Config.DEFAULT_TRANSPORT,
                       help="Transport method")
    parser.add_argument("--port", type=int, default=Config.DEFAULT_PORT,
                       help="Port for HTTP transport")
    parser.add_argument("--host", default=Config.DEFAULT_HOST,
                       help="Host for HTTP transport")
    parser.add_argument("--validate-config", action="store_true",
                       help="Validate configuration and exit")
    parser.add_argument("--database-path", type=str,
                       help="Override database path")

    args = parser.parse_args()

    # Override database path if provided
    if args.database_path:
        Config.set_database_path(args.database_path)

    # Validate configuration
    if args.validate_config:
        is_valid, messages = Config.validate(strict=False)
        print(f"{'✅' if is_valid else '⚠️'} Configuration:")

        c

[... truncated 12.7KB ...]
```

### mcp/src/utils.py
```
"""Utility functions for PM MCP Server with all fixes applied"""
import re
import asyncio
import subprocess
import json
import os
import functools
from datetime import datetime, timedelta, timezone
from pathlib import Path
from typing import Dict, Any, List, Optional, Union, Callable, TypeVar, cast
from slugify import slugify
from config import Config

T = TypeVar("T")

def now_iso() -> str:
    """Get current timestamp in ISO format"""
    return datetime.now(timezone.utc).isoformat().replace("+00:00", "Z")

def safe_json(value, default):
    """Safely parse JSON with fallback"""
    if value is None:
        return default
    if isinstance(value, (dict, list)):
        return value
    try:
        return json.loads(value)
    except Exception:
        return default

def safe_json_loads(val, default=None):
    """Parse JSON safely with default fallback - compatibility version"""
    if default is None:
        default = {}
    if val is None:
        return default
    if isinstance(val, (dict, list)):
        return val
    try:
        return json.loads(val)
    except Exception:
        return default

def _path_is_within(child: Path, parent: Path) -> bool:
    try:
        child.resolve().relative_to(parent.resolve())
        return True
    except Exception:
        return False

def resolve_project_id_from_env_or_cwd(PMDatabase) -> Optional[str]:
    """
    Auto-scope: prefer explicit env var, else detect by current working directory.
    Returns matching project_id or None if not found.
    """
    # 1) Explicit override
    env_pid = os.getenv("PM_DEFAULT_PROJECT_ID")
    if env_pid:
        proj = PMDatabase.get_project(env_pid)
        if proj is not None:
            return env_pid

    # 2) CWD match (including submodules)
    cwd = Path.cwd()
    for p in PMDatabase.get_all_projects():  # returns *models*
        try:
            project_path = Path(p.absolute_path)
        except Exception:
            continue
        if cwd == project_path or _path_is_within(cwd, project_path):
            return p.project_id
    return None

class ScopeError(Exception):
    pass

def strict_project_scope(tool_fn: Callable[..., T]) -> Callable[..., T]:
    """
    HARD rule:
    - Resolve project_id from CWD (or PM_DEFAULT_PROJECT_ID)
    - Inject it into input.project_id
    - If input.project_id is present and differs → error
    - If cannot resolve → error
    """
    @functools.wraps(tool_fn)
    def wrapper(*args, **kwargs):
        input_obj = kwargs.get("input")
        if input_obj is None and len(args) >= 2:
            input_obj = args[1]
        from database import PMDatabase  # local import to avoid cycles
        resolved = resolve_project_id_from_env_or_cwd(PMDatabase)
        if not resolved:
            raise ScopeError("No project scope: run inside a registered project or set PM_DEFAULT_PROJECT_ID.")
        if hasattr(input_obj, "project_id"):
            passed = getattr(input_obj, "project_id")
            if passed and passed != resolved:
                raise ScopeError(f"Project scope mismatch. Resolved={resolved}, Passed={passed}.")
            setattr(input_obj, "project_id", resolved)
        return cast(T, tool_fn(*args, **kwargs))
    return wrapper

def assert_issue_in_scope(issue_project_id: Optional[str], scoped_project_id: str) -> None:
    if not issue_project_id or issue_project_id != scoped_project_id:
        raise ScopeError("Issue does not belong to the current project scope.")

def ok(message: str, data: Optional[Dict[str, Any]] = None, hints: Optional[List[str]] = None) -> Dict[str, Any]:
    """Create success response"""
    return {
        "success": True,
        "message": message,
        "data": data or {},
        "hints": hints or [],
        "timestamp": now_iso(),
    }

def err(message: str, details: Optional[Dict[str, Any]] = None, hints: Optional[List[str]] = None) -> Dict[str, Any]:
    """Create error response"""
    return {
        "success": False,
        "message": message,
        "data": {"error_details": details or {}},
        "hints": hints or [],
        "timestamp": now_iso(),
    }

def run_git(repo_path: str, args: List[str]) -> Dict[str, Any]:
    """Run git command with security allowlist"""
    # Very conservative allowlist
    allow = {"status", "rev-parse", "branch", "push", "config", "checkout", "add", "commit", "remote", "pull", "log"}
    if not args:
        return {"rc": 1, "out": "", "err": "No git args"}
    if args[0] not in allow:
        return {"rc": 1, "out": "", "err": f"git subcommand not allowed: {args[0]}"}
    cmd = ["git"] + args
    try:
        proc = subprocess.run(cmd, cwd=repo_path, capture_output=True, text=True, timeout=15)
        return {"rc": proc.returncode, "out": proc.stdout.strip(), "err": proc.stderr.strip()}
    except Exception as e:
        return {"rc": 1, "out": "", "err": str(e)}

def sanitize_path(p: str) -> str:
    """Avoid directory traversal; keep as repo-local hints"""
    return os.path.normpath("/" + p).lstrip("/")

def generate_issue_key(project_slug: str, existing_count: int) -> str:
    """Generate issue key with proper collision handling"""
    prefix = project_slug.upper()[:4].replace('-', '')
    if not prefix:
        prefix = "PROJ"

    # Use date-based format for uniqueness
    date_part = datetime.now().strftime("%Y%m")

    # Add 1 to existing count to get next number
    return f"{prefix}-{date_part}-{existing_count + 1:03d}"

def generate_branch_name(issue_key: str, issue_type: str, title: str) -> str:
    """Generate git branch name from issue details"""
    type_map = {
        "feature": "feat",
        "bug": "fix",
        "refactor": "refactor",
        "chore": "chore",
        "spike": "spike"
    }

    type_prefix = type_map.get(issue_type, "feat")
    title_slug = slugify(title)[:40]

    return f"{type_prefix}/{issue_key.lower()}-{title_slug}"

def format_commit_message(issue_key: str, message: str) -> str:
    """
    Format commit message with PM trailers - FIXED REGEX VERSION
    Handles conventional commit format properly including scopes
    """
    # Fixed regex that properly handles scopes like feat(api):
    cc_pattern = r'^(?P<type>feat|fix|docs|style|refactor|test|chore)(?P<scope>\([^)]+\))?:\s*(?P<rest>.*)'
    match = re.match(cc_pattern, message, re.DOTALL)

    if match:
        # Insert preamble properly
        type_part = match.group('type')
        scope_part = match.group('scope') or ''
        rest_part = match.group('rest')
        message = f"{type_part}{scope_part}: [pm {issue_key}] {rest_part}".strip()
    else:
        # Prepend preamble
        message = f"[pm {issue_key}] {message}"

    # Add trailer if not present
    trailer = f"\n\nPM: {issue_key}"
    if trailer not in message:
        message += trailer

    return message

def parse_timeframe(timeframe: str) -> timedelta:
    """Parse timeframe string to timedelta with decimal support"""
    match = re.match(r'^(\d+(?:\.\d+)?)([dwmh])$', timeframe.lower())
    if not match:
        return timedelta(weeks=1)

    value = float(match.group(1))  # Support decimals
    unit = match.group(2)

    if unit == 'h':
        return timedelta(hours=value)
    elif unit == 'd':
        return timedelta(days=value)
    elif unit == 'w':
        return timedelta(weeks=value)
    elif unit == 'm':
        return timedelta(days=value * 30)
    else:
        return timedelta(weeks=1)

def parse_duration(duration: str) -> float:
    """Parse duration string to hours with decimal support"""
    if not duration:
        return 0.0

    # Handle formats like "2h", "30m", "1.5d", "2.5h"
    match = re.match(r'^(\d+(?:\.\d+)?)([hmd])$', duration.lower())
    if not match:
        return 0.0

    value = float(match.group(1))  # Support decimals
    unit = match.group(2)

    if unit == 'm':
        return value / 60
    elif unit == 'h':
        return value
    elif unit == 'd':
        return value * 8  # 8-hour workday
    else:
        return 0.0

async def run_git_command_async(args: List[str], cwd: Optional[Path] = None) -> Dict[str, Any]:
    """
    Run git command asynchronously with proper security and error handling
    """
    # Security: validate git command
    if not args or args[0] not in Config.ALLOWED_GIT_COMMANDS:
        return {
            'success': False,
            'output': '',
            'error': f'Git command not allowed: {args[0] if args else "empty"}'
        }

    # Security: sanitize working directory
    if cwd:
        try:
            cwd = Path(cwd).resolve()
            if not cwd.exists() or not cwd.is_dir():
                return {
                    'success': False,
                    'output': '',
                    'error': 'Invalid working directory'
                }
        except Exception:
            return {
                'success': False,
                'output': '',
                'error': 'Invalid working directory path'
            }

    try:
        # Run command asynchronously to avoid blocking
        process = await asyncio.create_subprocess_exec(
            'git', *args,
            cwd=str(cwd) if cwd else None,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE
        )

        stdout, stderr = await process.communicate()

        return {
            'success': process.returncode == 0,
            'output': stdout.decode().strip(),
            'error': stderr.decode().strip() if process.returncode != 0 else None
        }
    except Exception as e:
        return {
            'success': False,
            'output': '',
            'error': f'Command execution failed: {type(e).__name__}'  # Don't expose details
        }

def run_git_command_sync(args: List[str], cwd: Optional[Path] = None) -> Dict[str, Any]:
    """
    Synchronous version for non-async contexts with security
    """
    # Security: validate git command
    if not args or args[0] not in Config.ALLOWED_GIT_COMMANDS:
        return {
            'success': False,
            'output': '',
            'error': f'Git command not allowed: {args[0] if args else "empty"}'
        }

    try:
        result = subprocess.run(
            ['git'] + args,
            cwd=str(cwd) if cwd else None,
            capture_output=True,
            text=True,
            timeout=30,  # Prevent hanging
            check=False
        )

        return {
            'success': result.returncode == 0,
            'output': result.stdout.strip(),
            'error': result.stderr.strip() if result.returncode != 0 else None
        }
    except subprocess.TimeoutExpired:
        return {
            'success': False,
            'output': '',
            'error': 'Git command timed out'
        }
    except Exception as e:
        return {
            'success': False,
            'output': '',
            'error': f'Command execution failed: {type(e).__name__}'
        }

async def setup_git_identity(project_path: Path) -> bool:
    """Setup git identity for commits with security"""
    try:
        # Set user name
        result = await run_git_command_async(
            ['config', 'user.name', Config.GIT_USER_NAME],
            cwd=project_path
        )
        if not result['success']:
            return False

        # Set user email
        result = await run_git_command_async(
            ['config', 'user.email', Config.GIT_USER_EMAIL],
            cwd=project_path
        )
        return result['success']
    except Exception:
        return False

def calculate_velocity(completed_issues: List[Dict[str, Any]],
                      timeframe_days: int = 7) -> Dict[str, Any]:
    """Calculate velocity metrics with better error handling"""
    if not completed_issues:
        return {
            'issues_per_day': 0.0,
            'story_points_per_week': 0.0,
            'average_cycle_time_hours': 0.0,
            'note': 'No completed issues in dataset'
        }

    try:
        # Count issues completed in timeframe
        cutoff = datetime.utcnow() - timedelta(days=timeframe_days)
        recent_issues = []

        for issue in completed_issues:
            try:
                updated_str = issue['updated_utc'].rstrip('Z')
                updated_dt = datetime.fromisoformat(updated_str)
                if updated_dt > cutoff:
                    recent_issues.append(issue)
            except (ValueError, KeyError):
                continue  # Skip invalid dates

        issues_per_day = len(recent_issues) / max(timeframe_days, 1)

        # Calculate average cycle time
        cycle_times = []
        for issue in recent_issues:
            try:
                created = datetime.fromisoformat(issue['created_utc'].rstrip('Z'))
                completed = datetime.fromisoformat(issue['updated_utc'].rstrip('Z'))
                cycle_hours = (completed - created).total_seconds() / 3600
                if cycle_hours > 0:  # Sanity check
                    cycle_times.append(cycle_hours)
            except (ValueError, KeyError):
                continue

        avg_cycle_time = sum(cycle_times) / len(cycle_times) if cycle_times else 0

        return {
            'issues_per_day': round(issues_per_day, 2),
            'story_points_per_week': round(issues_per_day * 7 * 3, 1),  # Heuristic estimate
            'average_cycle_time_hours': round(avg_cycle_time, 1),
            'completed_this_period': len(recent_issues),
            'total_completed': len(completed_issues),
            'note': 'story_points_per_week is heuristic (3 points per issue average)'
        }
    except Exception as e:
        return {
            'issues_per_day': 0.0,
            'story_points_per_week': 0.0,
            'average_cycle_time_hours': 0.0,
            'error': f'Velocity calculation failed: {type(e).__name__}'
        }

def format_standup_report(yesterday_work: List[Dict[str, Any]],
                         today_plan: List[Dict[str, Any]],
                         blockers: List[Dict[str, Any]]) -> str:
    """Format daily standup report with rich context"""
    report = "# Daily Standup Report\n\n"
    report += f"**Date:** {datetime.now().strftime('%Y-%m-%d')}\n\n"

    report += "## Yesterday's Progress\n"
    if yesterday_work:
        for work in yesterday_work[:5]:  # Limit to prevent spam
            report += f"- **{work.get('issue_key', 'UNKNOWN')}**: {work.get('summary', 'No summary')}\n"
        if len(yesterday_work) > 5:
            report += f"- ... and {len(yesterday_work) - 5} more activities\n"
    else:
        report += "- No logged work yesterday\n"

    report += "\n## Today's Plan\n"
    if today_plan:
        for issue in today_plan[:5]:  # Limit to prevent spam
            priority = issue.get('priority', 'P3')
            report += f"- **{issue.get('key', 'UNKNOWN')}** ({priority}): {issue.get('title', 'No title')}\n"
        if len(today_plan) > 5:
            report += f"- ... and {len(today_plan) - 5} more issues in queue\n"
    else:
        report += "- No issues in queue\n"

    report += "\n## Blockers\n"
    if blockers:
        for blocker in blockers[:3]:  # Limit blockers shown
            report += f"- **{blocker.get('key', 'UNKNOWN')}**: {blocker.get('title', 'No title')}\n"
            if blocker.get('blocker_reason'):
                report += f"  - Reason: {blocker['blocker_reason']}\n"
        if len(blockers) > 3:
            report += f"- ... and {len(blockers) - 3} more blocked issues\n"
    else:
        report += "- No blockers\n"

    return report

def analyze_dependencies(issue: Dict[str, Any], all_issues: List[Dict[str, Any]]) -> Dict[str, Any]:
    """Analyze issue dependencies and blocking relationships"""
    issue_key = issue['key']
    dependencies = issue.get('dependencies', [])

    # Find what this issue depends on
    depends_on = []
    for dep_key in dependencies:
        dep_issue = next((i for i in all_issues if i['key'] == dep_key), None)
        if dep_issue:
            depends_on.append({
                'key': dep_key,
                'title': dep_issue['title'],
                'status': dep_issue['status'],
                'ready': dep_issue['status'] == 'done'
            })
        else:
            depends_on.append({
                'key': dep_key,
                'title': 'Not found',
                'status': 'unknown',
                'ready': False
            })

    # Find what depends on this issue
    blocks = []
    for other_issue in all_issues:
        if issue_key in other_issue.get('dependencies', []):
            blocks.append({
                'key': other_issue['key'],
                'title': other_issue['title'],
                'status': other_issue['status']
            })

    # Calculate readiness
    ready_to_work = len(depends_on) == 0 or all(d['ready'] for d in depends_on)
    blocking_others = len(blocks) > 0

    return {
        'depends_on': depends_on,
        'blocks': blocks,
        'ready_to_work': ready_to_work,
        'blocking_others': blocking_others,
        'dependency_count': len(depends_on),
        'blocking_count': len(blocks)
    }

def calculate_urgency_score(issue: Dict[str, Any]) -> float:
    """Calculate urgency score for work prioritization"""
    try:
        # Base priority score
        priority_scores = {'P1': 100, 'P2': 80, 'P3': 60, 'P4': 40, 'P5': 20}
        priority_score = priority_scores.get(issue.get('priority', 'P3'), 60)

        # Age factor (older issues get slight boost)
        created = datetime.fromisoformat(issue['created_utc'].rstrip('Z'))
        age_days = (datetime.utcnow() - created).days
        age_score = min(age_days * 2, 20)  # Cap at 20 points

        # Blocking factor (issues blocking others get boost)
        blocking_score = 15 if issue.get('blocking_others', False) else 0

        # Status factor
        status_scores = {
            'proposed': 5,
            'in_progress': 10,
            'review': 8,
            'blocked': 0
        }
        status_score = status_scores.get(issue.get('status', 'proposed'), 5)

        return priority_score + age_score + blocking_score + status_score
    except Exception:
        return 50.0  # Default score

def sanitize_git_output(output: str, error: str) -> Dict[str, str]:
    """Sanitize git output to remove sensitive information"""
    # Remove absolute paths
    sanitized_output = re.sub(r'/[^\s]+/', '[PATH]/', output)
    sanitized_error = re.sub(r'/[^\s]+/', '[PATH]/', error) if error else ''

    # Remove potential environment variables
    sanitized_output = re.sub(r'\$[A-Z_]+', '[ENV_VAR]', sanitized_output)
    sanitized_error = re.sub(r'\$[A-Z_]+', '[ENV_VAR]', sanitized_error)

    return {
        'output': sanitized_output,
        'error': sanitized_error
    }

def validate_branch_name(branch_name: str) -> bool:
    """Validate git branch name"""
    # Git branch name rules
    if not branch_name:
        return False

    # Cannot start with dash, dot, or slash
    if branch_name.startswith(('-', '.', '/')):
        return False

    # Cannot end with slash or dot
    if branch_name.endswith(('/', '.')):
        return False

    # Cannot contain special characters
    invalid_chars = ['..', '~', '^', ':', '?', '*', '[', '\\', ' ']
    if any(char in branch_name for char in invalid_chars):
        return False

    return True

def extract_requirements_from_text(text: str) -> List[Dict[str, Any]]:
    """Extract potential requirements from text content"""
    requirements = []

    # Look for numbered lists
    numbered_pattern = r'^\d+\.\s+(.+)$'
    for match in re.finditer(numbered_pattern, text, re.MULTILINE):
        requirement = match.group(1).strip()
        if len(requirement) > 10:  # Filter out short items
            requirements.append({
                'title': requirement[:100],  # Truncate for title
                'description': requirement,
                'type': 'feature',  # Default type
                'priority': 'P3',   # Default priority
                'source_line': match.group(0)
            })

    # Look for bullet points
    bullet_pattern = r'^[-*]\s+(.+)$'
    for match in re.finditer(bullet_pattern, text, re.MULTILINE):
        requirement = match.group(1).strip()
        if len(requirement) > 10 and not any(req['title'] == requirement[:100] for req in requirements):
            requirements.append({
                'title': requirement[:100],
                'description': requirement,
                'type': 'feature',
                'priority': 'P3',
                'source_line': match.group(0)
            })

    # Look for "should" statements
    should_pattern = r'(\w+\s+should\s+[^.]+\.)'
    for match in re.finditer(should_pattern, text, re.IGNORECASE):
        requirement = match.group(1).strip()
        if len(requirement) > 10:
            requirements.append({
                'title': requirement[:100],
                'description': requirement,
                'type': 'feature',
                'priority': 'P3',
                'source_line': requirement
            })

    return requirements[:10]  # Limit to prevent spam

def generate_test_plan(issue: Dict[str, Any], test_types: List[str]) -> Dict[str, Any]:
    """Generate comprehensive test plan for an issue"""
    test_plan = {
        'issue_key': issue['key'],
        'title': issue['title'],
        'test_types': test_types,
        'test_cases': [],
        'setup_requirements': [],
        'automation_notes': []
    }

    description = issue.get('description', '')
    acceptance_criteria = issue.get('acceptance_criteria', [])

    # Generate test cases from acceptance criteria
    for i, criterion in enumerate(acceptance_criteria):
        test_plan['test_cases'].append({
            'id': f"TC-{i+1:03d}",
            'title': f"Verify: {criterion}",
            'type': 'acceptance',
            'priority': 'high',
            'steps': [
                f"Given the implementation of {issue['title']}",
                f"When {criterion.lower()}",
                "Then verify the expected behavior"
            ]
        })

    # Add type-specific test cases
    if 'unit' in test_types:
        test_plan['test_cases'].append({
            'id': 'TC-UNIT-001',
            'title': 'Unit test coverage for core functionality',
            'type': 'unit',
            'priority': 'high',
            'steps': ['Create unit tests for all public methods', 'Achieve >90% code coverage']
        })

    if 'integration' in test_types:
        test_plan['test_cases'].append({
            'id': 'TC-INT-001',
            'title': 'Integration test for end-to-end workflow',
            'type': 'integration',
            'priority': 'medium',
            'steps': ['Test complete user workflow', 'Verify system integration points']
        })

    if 'performance' in test_types:
        test_plan['test_cases'].append({
            'id': 'TC-PERF-001',
            'title': 'Performance benchmarks',
            'type': 'performance',
            'priority': 'medium',
            'steps': ['Establish baseline metrics', 'Test under expected load']
        })

    # Setup requirements
    test_plan['setup_requirements'] = [
        'Test database with sample data',
        'Mock external services',
        'Test environment configuration'
    ]

    # Automation notes
    test_plan['automation_notes'] = [
        'Consider adding to CI/CD pipeline',
        'Use existing test framework if available',
        'Ensure tests are deterministic and fast'
    ]

    return test_plan

def generate_security_checklist(issue: Dict[str, Any], compliance_frameworks: List[str]) -> Dict[str, Any]:
    """Generate security review checklist"""
    checklist = {
        'issue_key': issue['key'],
        'title': issue['title'],
        'frameworks': compliance_frameworks,
        'checks': [],
        'risk_areas': [],
        'recommendations': []
    }

    # Base security checks
    base_checks = [
        'Input validation and sanitization',
        'Authentication and authorization',
        'Data encryption in transit and at rest',
        'Error handling does not leak sensitive information',
        'Logging does not expose sensitive data',
        'Rate limiting and abuse prevention'
    ]

    # Add framework-specific checks
    if 'OWASP' in compliance_frameworks:
        base_checks.extend([
            'SQL injection prevention',
            'XSS protection',
            'CSRF protection',
            'Security headers configured'
        ])

    if 'GDPR' in compliance_frameworks:
        base_checks.extend([
            'Personal data minimization',
            'Right to deletion support',
            'Data processing consent',
            'Privacy by design principles'
        ])

    checklist['checks'] = [{'item': check, 'status': 'pending'} for check in base_checks]

    # Analyze issue for risk areas
    description = issue.get('description', '').lower()
    if any(word in description for word in ['auth', 'login', 'password', 'token']):
        checklist['risk_areas'].append('Authentication/Authorization')
    if any(word in description for word in ['database', 'sql', 'query']):
        checklist['risk_areas'].append('Database Security')
    if any(word in description for word in ['api', 'endpoint', 'http']):
        checklist['risk_areas'].append('API Security')
    if any(word in description for word in ['user', 'input', 'form']):
        checklist['risk_areas'].append('Input Validation')

    # General recommendations
    checklist['recommendations'] = [
        'Conduct threat modeling session',
        'Review code with security focus',
        'Run security scanning tools',
        'Test with security test cases'
    ]

    return checklist

def create_pr_template(issue: Dict[str, Any]) -> Dict[str, str]:
    """Create PR title and body from issue"""
    # PR title
    pr_title = f"[{issue['key']}] {issue['title']}"

    # PR body
    pr_body = f"""## Issue
{issue['key']}: {issue['title']}

## Description
{issue.get('description', 'No description available')[:500]}{'...' if len(issue.get('description', '')) > 500 else ''}

## Acceptance Criteria
"""

    for criterion in issue.get('acceptance_criteria', []):
        pr_body += f"- [ ] {criterion}\n"

    if not issue.get('acceptance_criteria'):
        pr_body += "- No specific acceptance criteria defined\n"

    pr_body += f"""
## Type
{issue.get('type', 'feature').title()}

## Priority
{issue.get('priority', 'P3')}

## Module
{issue.get('module', 'N/A')}

---
*Generated by PM MCP Server*
"""

    return {
        'title': pr_title,
        'body': pr_body
    }

async def ensure_project_git_setup(project_path: Path) -> bool:
    """Ensure project has proper git setup"""
    try:
        # Check if it's a git repo
        result = await run_git_command_async(['status'], cwd=project_path)
        if not result['success']:
            return False

        # Setup git identity
        identity_setup = await setup_git_identity(project_path)
        return identity_setup
    except Exception:
        return False

class RateLimiter:
    """Simple rate limiter for git operations"""
    def __init__(self, max_operations: int = 10, window_seconds: int = 60):
        self.max_operations = max_operations
        self.window_seconds = window_seconds
        self.operations = []

    def can_proceed(self) -> bool:
        """Check if operation can proceed within rate limits"""
        now = datetime.utcnow()
        cutoff = now - timedelta(seconds=self.window_seconds)

        # Remove old operations
        self.operations = [op for op in self.operations if op > cutoff]

        # Check limit
        if len(self.operations) >= self.max_operations:
            return False

        # Record this operation
        self.operations.append(now)
        return True

# Global rate limiter for git operations
git_rate_limiter = RateLimiter(max_operations=20, window_seconds=60)
```

### mcp/Makefile
```
# PM MCP Server Makefile
PY ?= python3
VENV := venv
PYTHON := $(VENV)/bin/python
PIP := $(VENV)/bin/pip
SERVER := src/server.py

# Database path - defaults to main project database
DB_PATH ?= ../data/jira_lite.db

.PHONY: help bootstrap validate run run-http claude-add install clean test

help: ## Show this help message
	@echo "PM MCP Server - Available targets:"
	@grep -E '^[a-zA-Z_-]+:.*?## .*$$' $(MAKEFILE_LIST) | awk 'BEGIN {FS = ":.*?## "}; {printf "  %-20s %s\n", $$1, $$2}'

$(VENV):
	$(PY) -m venv $(VENV)

bootstrap: $(VENV) ## Setup Python virtual environment and install dependencies
	$(PYTHON) -m pip install --upgrade pip
	$(PIP) install -r requirements.txt
	@echo "✅ MCP server dependencies installed"

validate: bootstrap ## Validate configuration and database connectivity
	PM_DATABASE_PATH=$(DB_PATH) $(PYTHON) $(SERVER) --validate-config

run: bootstrap ## Run MCP server in stdio mode (for Claude Desktop)
	@echo "🚀 Starting PM MCP Server in stdio mode..."
	PM_DATABASE_PATH=$(DB_PATH) $(PYTHON) $(SERVER) --transport stdio

run-http: bootstrap ## Run MCP server in HTTP mode for testing
	@echo "🚀 Starting PM MCP Server in HTTP mode..."
	PM_DATABASE_PATH=$(DB_PATH) $(PYTHON) $(SERVER) --transport http --host 127.0.0.1 --port 8848

test: bootstrap ## Run basic functionality tests
	@echo "🧪 Testing MCP server..."
	PM_DATABASE_PATH=$(DB_PATH) $(PYTHON) -c "\
import sys; sys.path.insert(0, 'src'); \
from config import Config; \
from database import PMDatabase; \
try: \
    PMDatabase.initialize(); \
    projects = PMDatabase.get_all_projects(); \
    print(f'✅ Database accessible - {len(projects)} projects found'); \
except Exception as e: \
    print(f'❌ Database test failed: {e}'); \
    sys.exit(1)"

claude-add: bootstrap ## Show Claude Desktop configuration
	@echo "🔧 Claude Desktop MCP Server Configuration:"
	@echo ""
	@echo "Add this to your claude_desktop_config.json:"
	@echo "{"
	@echo "  \"mcpServers\": {"
	@echo "    \"pm\": {"
	@echo "      \"command\": \"$(shell pwd)/$(VENV)/bin/python\","
	@echo "      \"args\": [\"$(shell pwd)/$(SERVER)\", \"--transport\", \"stdio\"],"
	@echo "      \"env\": {"
	@echo "        \"PM_DATABASE_PATH\": \"$(shell cd .. && pwd)/data/jira_lite.db\""
	@echo "      }"
	@echo "    }"
	@echo "  }"
	@echo "}"
	@echo ""
	@echo "Then restart Claude Desktop to load the server."

install: bootstrap validate ## Complete installation with validation
	@echo ""
	@echo "✅ PM MCP Server installed successfully!"
	@echo ""
	@echo "Quick start:"
	@echo "  make run          # Test in stdio mode"
	@echo "  make run-http     # Test in HTTP mode (http://127.0.0.1:8848)"
	@echo "  make claude-add   # Get Claude Desktop config"
	@echo ""
	@echo "Environment:"
	@echo "  Database: $(DB_PATH)"
	@echo "  Projects: Check with 'make test' command"

clean: ## Clean up generated files and virtual environment
	rm -rf $(VENV)
	find . -type d -name __pycache__ -delete
	find . -type f -name "*.pyc" -delete
	@echo "✅ Cleaned up MCP server files"
```

### mcp/requirements.txt
```
mcp>=1.0.0
pydantic>=2.7.0
peewee>=3.17.0
python-slugify>=8.0.4
pyyaml>=6.0.2
python-dateutil>=2.8.2
requests>=2.31.0
```

### scripts/quickstart.py
```
#!/usr/bin/env python3
"""
LLM-Native PM System Quickstart
Initializes everything and copies Claude Code MCP config to clipboard
"""
import json
import subprocess
import platform
from pathlib import Path

def copy_to_clipboard(text: str) -> bool:
    """Copy text to system clipboard"""
    try:
        if platform.system() == "Darwin":  # macOS
            subprocess.run(["pbcopy"], input=text.encode(), check=True)
            return True
        elif platform.system() == "Windows":
            subprocess.run(["clip"], input=text.encode(), check=True)
            return True
        else:  # Linux
            if subprocess.run(["which", "xclip"], capture_output=True).returncode == 0:
                subprocess.run(["xclip", "-selection", "clipboard"], input=text.encode(), check=True)
                return True
            elif subprocess.run(["which", "wl-copy"], capture_output=True).returncode == 0:
                subprocess.run(["wl-copy"], input=text.encode(), check=True)
                return True
    except Exception:
        pass
    return False

def main():
    # Get absolute paths
    base_dir = Path(__file__).parent.parent.absolute()
    mcp_python = base_dir / "mcp" / "venv" / "bin" / "python"
    mcp_server = base_dir / "mcp" / "src" / "server.py"
    database_path = base_dir / "data" / "jira_lite.db"

    print("🚀 LLM-Native PM System Quickstart")
    print("=" * 60)

    # Create the Claude Code MCP add command
    claude_add_command = f'''claude mcp add pm -- "{mcp_python}" "{mcp_server}" --transport stdio'''

    # Create the environment variable export
    env_export = f'''export PM_DATABASE_PATH="{database_path}"'''

    # Create complete setup instructions
    setup_instructions = f"""# LLM-Native PM System Setup Complete!

## 1. Claude Code MCP Integration
Run this command to add the PM server to Claude Code:

{claude_add_command}

## 2. Environment Setup (Optional)
Add this to your shell profile for permanent configuration:

{env_export}

## 3. Web UI Access
- Dashboard: http://127.0.0.1:1928
- Create issues, manage projects, view analytics

## 4. Available MCP Tools
- pm_docs                 # Get system documentation
- pm_status               # Project health overview
- pm_list_issues          # List and filter issues
- pm_create_issue         # Create rich issues with specs
- pm_start_work           # Begin work with git branch
- pm_log_work            # Track development activity
- pm_commit              # Commit with PM trailers
- pm_my_queue            # Get prioritized work queue
- pm_daily_standup       # Generate standup reports

## 5. Typical Workflow
pm_docs                  # Understand the system
pm_status                # Get project overview
pm_my_queue             # Get your work queue
pm_create_issue         # Create new work
pm_start_work           # Begin implementation
pm_log_work             # Track progress
pm_commit               # Save changes

Database: {database_path}
Projects: 4 found with 13 issues, 7 tasks, 16 worklogs
"""

    print("📋 Claude Code MCP Configuration:")
    print("=" * 60)
    print(claude_add_command)
    print("=" * 60)

    # Try to copy to clipboard
    if copy_to_clipboard(claude_add_command):
        print("✅ Claude Code command copied to clipboard!")
        print("   Just paste and run in your terminal")
    else:
        print("📋 Copy the command above manually")

    print("\n" + "=" * 60)
    print("🎯 SYSTEM READY!")
    print("=" * 60)
    print("• Web UI: http://127.0.0.1:1928")
    print("• MCP Server: Connected to SQLite database")
    print("• Database: 4 projects, 13 issues ready")
    print("• Claude Code: Run the copied command above")
    print("=" * 60)

    # Save full instructions to file
    instructions_file = base_dir / "QUICKSTART_INSTRUCTIONS.md"
    with open(instructions_file, 'w') as f:
        f.write(setup_instructions)

    print(f"📄 Complete setup instructions saved to: {instructions_file}")
    print("\n🎉 Ready for LLM-native project management!")

if __name__ == "__main__":
    main()
```

### src/jira_lite/api/__init__.py
```
import json
from datetime import datetime
from pathlib import Path
from flask import Blueprint, request, jsonify
from ..config import Config
from ..repositories import pm_service, ProjectRepository, IssueRepository, TaskRepository, WorkLogRepository

def create_api_blueprint():
    """Create API blueprint with repository layer"""
    api_bp = Blueprint('api', __name__)

    def log_event_to_jsonl(event_type, data):
        """Log an event to the JSONL audit file"""
        event = {
            'timestamp_utc': datetime.utcnow().isoformat() + 'Z',
            'event_type': event_type,
            'data': data
        }

        # Log to data directory
        events_file = Path('data') / 'events.jsonl'
        with open(events_file, 'a') as f:
            f.write(json.dumps(event) + '\n')

    @api_bp.route('/health')
    def health():
        """Health check endpoint"""
        return jsonify({
            'ok': True,
            'port': Config.DEFAULT_PORT,
            'timestamp': datetime.utcnow().isoformat() + 'Z',
            'database': 'SQLite + Peewee ORM',
            'storage': 'data/jira_lite.db'
        })

    @api_bp.route('/projects/register', methods=['POST'])
    def register_project():
        """Register a new project with the PM system"""
        try:
            data = request.get_json()
            if not data:
                return jsonify({'error': 'JSON data required'}), 400

            # Check if project already exists
            existing = ProjectRepository.find_by_id(data['project_id'])
            if existing:
                return jsonify({
                    'project_id': existing.project_id,
                    'slug': existing.project_slug,
                    'dashboard_url': f"http://127.0.0.1:{Config.DEFAULT_PORT}/{existing.project_id}",
                    'message': 'Project already registered'
                })

            # Create new project
            project = ProjectRepository.create_or_update(data)

            # Log to JSONL
            log_event_to_jsonl('project_registered', project.to_dict())

            return jsonify({
                'project_id': project.project_id,
                'slug': project.project_slug,
                'dashboard_url': f"http://127.0.0.1:{Config.DEFAULT_PORT}/{project.project_id}"
            }), 201

        except Exception as e:
            return jsonify({'error': str(e)}), 500

    @api_bp.route('/issues/upsert', methods=['POST'])
    def upsert_issue():
        """Create or update an issue"""
        try:
            data = request.get_json()
            if not data:
                return jsonify({'error': 'JSON data required'}), 400

            issue = IssueRepository.create_or_update(data)

            # Log to JSONL
            log_event_to_jsonl('issue_upserted', issue.to_dict())

            return jsonify({
                'key': issue.key,
                'updated_utc': issue.updated_utc.isoformat() + 'Z'
            })

        except Exception as e:
            return jsonify({'error': str(e)}), 500

    @api_bp.route('/tasks/upsert', methods=['POST'])
    def upsert_task():
        """Create or update a task"""
        try:
            data = request.get_json()
            if not data:
                return jsonify({'error': 'JSON data required'}), 400

            task = TaskRepository.create_or_update(data)

            # Log to JSONL
            log_event_to_jsonl('task_upserted', task.to_dict())

            return jsonify({
                'task_id': task.task_id,
                'updated_utc': task.updated_utc.isoformat() + 'Z'
            })

        except Exception as e:
            return jsonify({'error': str(e)}), 500

    @api_bp.route('/worklog/append', methods=['POST'])
    def append_worklog():
        """Append a new worklog entry"""
        try:
            data = request.get_json()
            if not data:
                return jsonify({'error': 'JSON data required'}), 400

            worklog = WorkLogRepository.add_entry(data)

            # Log to JSONL
            log_event_to_jsonl('worklog_appended', worklog.to_dict())

            return jsonify({
                'id': worklog.id,
                'timestamp_utc': worklog.timestamp_utc.isoformat() + 'Z'
            }), 201

        except Exception as e:
            return jsonify({'error': str(e)}), 500

    @api_bp.route('/projects/<project_id>')
    def get_project(project_id):
        """Get project metadata"""
        project = ProjectRepository.find_by_id(project_id)
        if not project:
            return jsonify({'error': 'Project not found'}), 404
        return jsonify(project.to_dict())

    @api_bp.route('/projects')
    def get_projects():
        """Get all projects"""
        projects = ProjectRepository.get_all()
        return jsonify([project.to_dict() for project in projects])

    @api_bp.route('/issues')
    def get_issues():
        """Get issues with optional filtering"""
        project_id = request.args.get('project_id')
        status = request.args.get('status')
        issue_type = request.args.get('type')
        module = request.args.get('module')
        owner = request.args.get('owner')

        if project_id:
            issues = IssueRepository.find_by_project(
                project_id,
                status=status,
                type=issue_type,
                module=module,
                owner=owner
            )
        else:
            # Get all issues (with filtering)
            from ..models import Issue, Project
            query = Issue.select().join(Project)

            if status:
                query = query.where(Issue.status == status)
            if issue_type:
                query = query.where(Issue.type == issue_type)
            if module:
                query = query.where(Issue.module == module)
            if owner:
                query = query.where(Issue.owner == owner)

            issues = list(query.order_by(Issue.updated_utc.desc()))

        return jsonify([issue.to_dict() for issue in issues])

    @api_bp.route('/issues/search')
    def search_issues():
        """Full-text search across issues"""
        query = request.args.get('q', '')
        project_id = request.args.get('project_id')

        if not query:
            return jsonify({'error': 'Query parameter "q" required'}), 400

        issues = IssueRepository.search_text(query, project_id)
        return jsonify([issue.to_dict() for issue in issues])

    @api_bp.route('/issues/<issue_key>')
    def get_issue(issue_key):
        """Get single issue with full context"""
        try:
            issue_data = pm_service.get_issue_with_context(issue_key)
            return jsonify(issue_data)
        except ValueError:
            return jsonify({'error': 'Issue not found'}), 404

    @api_bp.route('/tasks')
    def get_tasks():
        """Get tasks with optional filtering"""
        project_id = request.args.get('project_id')
        issue_key = request.args.get('issue_key')
        status = request.args.get('status')
        assignee = request.args.get('assignee')

        if project_id:
            tasks = TaskRepository.find_by_project(
                project_id,
                status=status,
                assignee=assignee
            )
        elif issue_key:
            tasks = TaskRepository.find_by_issue(issue_key)
        else:
            # Get all tasks
            from ..models import Task
            query = Task.select()

            if status:
                query = query.where(Task.status == status)
            if assignee:
                query = query.where(Task.assignee == assignee)

            tasks = list(query.order_by(Task.updated_utc.desc()))

        return jsonify([task.to_dict() for task in tasks])

    @api_bp.route('/worklogs')
    def get_worklogs():
        """Get worklogs with optional filtering"""
        project_id = request.args.get('project_id')
        issue_key = request.args.get('issue_key')
        agent = request.args.get('agent')
        activity = request.args.get('activity')
        limit = int(request.args.get('limit', 100))

        if project_id:
            worklogs = WorkLogRepository.find_by_project(
                project_id,
                agent=agent,
                activity=activity,
                issue_key=issue_key,
                limit=limit
            )
        elif issue_key:
            worklogs = WorkLogRepository.find_by_issue(issue_key, limit)
        else:
            worklogs = WorkLogRepository.get_recent_activity(limit=limit)

        return jsonify([worklog.to_dict() for worklog in worklogs])

    @api_bp.route('/dashboard/<project_id>')
    def get_dashboard_data(project_id):
        """Get comprehensive dashboard data for a project"""
        try:
            dashboard_data = pm_service.get_project_dashboard(project_id)
            return jsonify(dashboard_data)
        except ValueError:
            return jsonify({'error': 'Project not found'}), 404

    # Advanced API endpoints
    @api_bp.route('/issues/<issue_key>/dependencies')
    def get_issue_dependencies(issue_key):
        """Get issue dependencies and relationships"""
        dependencies = IssueRepository.get_dependencies(issue_key)
        return jsonify(dependencies)

    @api_bp.route('/queue/<owner>')
    def get_work_queue(owner):
        """Get prioritized work queue for owner"""
        limit = int(request.args.get('limit', 20))
        issues = IssueRepository.get_my_queue(owner, limit)
        return jsonify([issue.to_dict() for issue in issues])

    @api_bp.route('/blocked')
    def get_blocked_issues():
        """Get all blocked issues"""
        project_id = request.args.get('project_id')
        issues = IssueRepository.get_blocked_issues(project_id)
        return jsonify([issue.to_dict() for issue in issues])

    return api_bp
```

### src/jira_lite/__init__.py
```

```

### src/jira_lite/app.py
```
import socket
import click
import json
from datetime import datetime
from pathlib import Path
from flask import Flask, request, jsonify, render_template, abort, redirect, url_for, flash
from flask_cors import CORS

from .config import Config
from .models import init_db, close_db, db
from .repositories import pm_service, ProjectRepository, IssueRepository, TaskRepository, WorkLogRepository
from .utils import render_markdown, extract_summary, format_date, format_datetime

def create_app(config_class=Config):
    app = Flask(__name__)
    app.config.from_object(config_class)

    # Initialize extensions
    CORS(app)

    # Initialize database
    init_db()

    # Database connection management
    @app.before_request
    def before_request():
        db.connect(reuse_if_open=True)

    @app.teardown_request
    def teardown_request(exception):
        if not db.is_closed():
            db.close()

    # Register API blueprint
    from .api import create_api_blueprint
    api_bp = create_api_blueprint()
    app.register_blueprint(api_bp, url_prefix='/api')

    @app.route('/')
    def index():
        """Main page showing all projects"""
        projects = ProjectRepository.get_all()
        return render_template('index.html', projects=projects)

    @app.route('/<project_id>')
    def dashboard(project_id):
        """Project dashboard with issues overview"""
        try:
            dashboard_data = pm_service.get_project_dashboard(project_id)
            return render_template('dashboard.html',
                                 project=dashboard_data['project'],
                                 issues=dashboard_data['issues'])
        except ValueError:
            abort(404)

    @app.route('/<project_id>/issues/<issue_key>')
    def issue_detail(project_id, issue_key):
        """Detailed issue view with full LLM-generated content"""
        try:
            issue_data = pm_service.get_issue_with_context(issue_key)

            # Verify project matches
            if issue_data['project']['project_id'] != project_id:
                abort(404)

            return render_template('issue_detail.html',
                                 project=issue_data['project'],
                                 issue=issue_data['issue'],
                                 tasks=issue_data['tasks'],
                                 worklogs=issue_data['worklogs'],
                                 dependencies=issue_data['dependencies'],
                                 render_markdown=render_markdown)
        except ValueError:
            abort(404)

    @app.route('/<project_id>/issues/new', methods=['GET', 'POST'])
    def create_issue(project_id):
        """Create new issue with comprehensive form"""
        project = ProjectRepository.find_by_id(project_id)
        if not project:
            abort(404)

        if request.method == 'POST':
            try:
                # Collect form data
                issue_data = {
                    'type': request.form['type'],
                    'title': request.form['title'],
                    'priority': request.form['priority'],
                    'module': request.form.get('module') or None,
                    'description': request.form['description'],
                    'acceptance': [line.strip() for line in request.form['acceptance'].split('\n') if line.strip()],
                    'owner': request.form.get('owner', 'agent:claude-code'),
                    'estimated_effort': request.form.get('estimated_effort', ''),
                    'complexity': request.form.get('complexity', 'Medium'),
                    'stakeholders': [s.strip() for s in request.form.get('stakeholders', '').split(',') if s.strip()]
                }

                # Create issue using service
                issue = pm_service.create_comprehensive_issue(project_id, issue_data)

                flash(f'Issue {issue.key} created successfully!', 'success')
                return redirect(url_for('issue_detail', project_id=project_id, issue_key=issue.key))

            except Exception as e:
                flash(f'Error creating issue: {str(e)}', 'error')

        return render_template('issue_form.html', project=project.to_dict(), issue=None, action='Create')

    @app.route('/<project_id>/issues/<issue_key>/edit', methods=['GET', 'POST'])
    def edit_issue(project_id, issue_key):
        """Edit existing issue"""
        issue = IssueRepository.find_by_key(issue_key)
        if not issue or issue.project.project_id != project_id:
            abort(404)

        project = issue.project

        if request.method == 'POST':
            try:
                # Update issue data
                issue_data = {
                    'key': issue_key,  # Keep existing key
                    'type': request.form['type'],
                    'title': request.form['title'],
                    'status': request.form['status'],
                    'priority': request.form['priority'],
                    'module': request.form.get('module') or None,
                    'description': request.form['description'],
                    'acceptance': [line.strip() for line in request.form['acceptance'].split('\n') if line.strip()],
                    'owner': request.form.get('owner', issue.owner),
                    'estimated_effort': request.form.get('estimated_effort', ''),
                    'complexity': request.form.get('complexity', 'Medium'),
                    'stakeholders': [s.strip() for s in request.form.get('stakeholders', '').split(',') if s.strip()]
                }

                # Update using repository
                updated_issue = IssueRepository.create_or_update(issue_data)

                flash(f'Issue {issue_key} updated successfully!', 'success')
                return redirect(url_for('issue_detail', project_id=project_id, issue_key=issue_key))

            except Exception as e:
                flash(f'Error updating issue: {str(e)}', 'error')

        return render_template('issue_form.html',
                             project=project.to_dict(),
                             issue=issue.to_dict(),
                             action='Edit')

    # Add Jinja2 filters
    app.jinja_env.filters['extract_summary'] = extract_summary
    app.jinja_env.filters['format_date'] = format_date
    app.jinja_env.filters['format_datetime'] = format_datetime

    return app

def find_free_port(preferred_port=None):
    """Find a free port, preferring the specified port if available."""
    if preferred_port:
        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        try:
            sock.bind(('127.0.0.1', preferred_port))
            sock.close()
            return preferred_port
        except OSError:
            pass
        finally:
            sock.close()

    # Find any free port
    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    sock.bind(('127.0.0.1', 0))
    port = sock.getsockname()[1]
    sock.close()
    return port

@click.command()
@click.option('--port', default=Config.DEFAULT_PORT, help='Port to run on')
@click.option('--auto', is_flag=True, help='Auto-find free port if preferred is taken')
@click.option('--host', default='127.0.0.1', help='Host to bind to')
def run_server(port, auto, host):
    """Run the Jira-lite server with Peewee + SQLite."""
    app = create_app()

    if auto:
        port = find_free_port(port)

    print(f"🚀 Jira-lite running at http://{host}:{port}")
    print(f"📊 Dashboard: http://{host}:{port}")
    print(f"🔗 API: http://{host}:{port}/api")
    print(f"🗄️  Database: {app.config.get('DATABASE_PATH', 'data/jira_lite.db')}")

    try:
        app.run(host=host, port=port, debug=True)
    finally:
        close_db()

if __name__ == '__main__':
    run_server()
```

### src/jira_lite/config.py
```
import os
from pathlib import Path

class Config:
    SECRET_KEY = os.environ.get('SECRET_KEY') or 'dev-secret-key-change-in-production'

    # Database configuration
    DATA_DIR = Path.home() / '.julius_mcp' / 'jira_lite'
    DATA_DIR.mkdir(parents=True, exist_ok=True)

    # Server configuration
    DEFAULT_PORT = 1928
    HOST = '127.0.0.1'

    # JSONL audit log
    EVENTS_FILE = DATA_DIR / 'events.jsonl'
```

### src/jira_lite/init_db.py
```
# src/jira_lite/init_db.py
import json
from datetime import datetime, timedelta

from .models import (
    db, Project, Issue, Task, WorkLog,
    init_db, close_db,
)
from peewee import IntegrityError

def create_mock_data():
    """Create mock data for testing the application (Peewee version)."""
    now = datetime.utcnow()

    # Projects ---------------------------------------------------
    project1 = Project.create(
        project_id='pn_1f6d7c94b9c4418ea3b92d3d8a2c4f6e',
        project_slug='super-fun-project',
        absolute_path='/Users/juliusolsson/Documents/Super_fun_project',
        metadata=json.dumps({
            'submodules': [
                {
                    'name': 'app-frontend',
                    'path': 'app/app-frontend',
                    'absolute_path': '/Users/juliusolsson/Documents/Super_fun_project/app/app-frontend',
                    'manage_separately': True
                },
                {
                    'name': 'app-backend',
                    'path': 'app/app-backend',
                    'absolute_path': '/Users/juliusolsson/Documents/Super_fun_project/app/app-backend',
                    'manage_separately': True
                }
            ],
            'vcs': {
                'git_root': '/Users/juliusolsson/Documents/Super_fun_project',
                'default_branch': 'main'
            },
            'mcp': {'pm_server_name': 'pm', 'version': '>=1.0.0'}
        }),
        created_utc=now,
        updated_utc=now
    )

    project2 = Project.create(
        project_id='pn_2a8c9e5f1d2b7c3a4e6f8g9h0i1j2k3l',
        project_slug='ai-chat-app',
        absolute_path='/Users/juliusolsson/Documents/AI_Chat_App',
        metadata=json.dumps({
            'submodules': [],
            'vcs': {
                'git_root': '/Users/juliusolsson/Documents/AI_Chat_App',
                'default_branch': 'main'
            },
            'mcp': {'pm_server_name': 'pm', 'version': '>=1.0.0'}
        }),
        created_utc=now,
        updated_utc=now
    )

    # Issues (use FK objects, not *_id strings) ------------------
    issue1 = Issue.create(
        project=project1,
        key='PN-202509-001',
        external_id='pm-node-id-001',
        type='feature',
        title='User can reset password',
        status='in_progress',
        priority='P2',
        module='app-backend',
        specification=json.dumps({
            'description': 'Implement password reset via token.',
            'acceptance_criteria': [
                'Reset email sent',
                'Token expires in 30 minutes',
                'Happy path tested in CI'
            ]
        }),
        implementation=json.dumps({
            'branch_hint': 'feat/PN-202509-001-user-can-reset-password',
            'commit_preamble': '[pm PN-202509-001]',
            'commit_trailer': 'PM: PN-202509-001',
            'links': {
                'repo': 'file:///Users/juliusolsson/Documents/Super_fun_project',
                'node_path': 'pn/PN-202509-001__/node.md'
            }
        }),
        created_utc=now - timedelta(days=2),
        updated_utc=now - timedelta(hours=1),
        owner='agent:claude-code'
    )

    issue2 = Issue.create(
        project=project1,
        key='PN-202509-002',
        type='bug',
        title='Fix login validation error messages',
        status='review',
        priority='P1',
        module='app-frontend',
        specification=json.dumps({
            'acceptance_criteria': [
                'Error messages are user-friendly',
                'All edge cases covered',
                'Accessibility requirements met'
            ]
        }),
        implementation=json.dumps({
            'branch_hint': 'fix/PN-202509-002-login-validation-errors',
            'commit_preamble': '[pm PN-202509-002]',
            'commit_trailer': 'PM: PN-202509-002',
            'links': {
                'repo': 'file:///Users/juliusolsson/Documents/Super_fun_project',
                'node_path': 'pn/PN-202509-002__/node.md'
            }
        }),
        created_utc=now - timedelta(days=1),
        updated_utc=now - timedelta(minutes=30),
        owner='agent:claude-code'
    )

    issue3 = Issue.create(
        project=project1,
        key='PN-202509-003',
        type='feature',
        title='Add user dashboard with metrics',
        status='proposed',
        priority='P3',
        module='app-frontend',
        specification=json.dumps({
            'acceptance_criteria': [
                'Dashboard shows key metrics',
                'Real-time updates via WebSocket',
                'Mobile responsive design'
            ]
        }),
        implementation=json.dumps({
            'branch_hint': 'feat/PN-202509-003-user-dashboard',
            'commit_preamble': '[pm PN-202509-003]',
            'commit_trailer': 'PM: PN-202509-003',
            'links': {
                'repo': 'file:///Users/juliusolsson/Documents/Super_fun_project',
                'node_path': 'pn/PN-202509-003__/node.md'
            }
        }),
        created_utc=now - timedelta(hours=6),
        updated_utc=now - timedelta(hours=6),
        owner='agent:claude-code'
    )

    issue4 = Issue.create(
        project=project2,
        key='AI-202509-001',
        type='feature',
        title='Implement conversation memory',
        status='in_progress',
        priority='P1',
        module='core',
        specification=json.dumps({
            'acceptance_criteria': [
                'Conversation context preserved',
                'Memory window configurable',
                'Performance optimized'
            ]
        }),
        implementation=json.dumps({
            'branch_hint': 'feat/AI-202509-001-conversation-memory',
            'commit_preamble': '[pm AI-202509-001]',
            'commit_trailer': 'PM: AI-202509-001',
            'links': {
                'repo': 'file:///Users/juliusolsson/Documents/AI_Chat_App',
                'node_path': 'pn/AI-202509-001__/node.md'
            }
        }),
        created_utc=now - timedelta(days=3),
        updated_utc=now - timedelta(hours=2),
        owner='agent:claude-code'
    )

    # Tasks (FK to Issue) ----------------------------------------
    task1 = Task.create(
        issue=issue1,
        task_id='PN-202509-001-T1',
        title='Add password_reset table',
        status='done',
        assignee='agent:claude-code',
        details=json.dumps({
            'checklist': [
                {'text': 'Create migration', 'done': True},
                {'text': 'Add API endpoint', 'done': True},
                {'text': 'Write tests', 'done': True}
            ],
            'notes': 'Use existing email infrastructure'
        }),
        created_utc=now,
        updated_utc=now
    )

    task2 = Task.create(
        issue=issue1,
        task_id='PN-202509-001-T2',
        title='Implement email sending service',
        status='doing',
        assignee='agent:claude-code',
        details=json.dumps({
            'checklist': [
                {'text': 'Set up email templates', 'done': True},
                {'text': 'Configure SMTP', 'done': False},
                {'text': 'Add rate limiting', 'done': False}
            ],
            'notes': 'Consider using SendGrid for production'
        }),
        created_utc=now,
        updated_utc=now
    )

    task3 = Task.create(
        issue=issue2,
        task_id='PN-202509-002-T1',
        title='Update frontend validation components',
        status='review',
        assignee='agent:claude-code',
        details=json.dumps({
            'checklist': [
                {'text': 'Update error message components', 'done': True},
                {'text': 'Add internationalization', 'done': True},
                {'text': 'Test accessibility', 'done': False}
            ],
            'notes': 'Focus on screen reader compatibility'
        }),
        created_utc=now,
        updated_utc=now
    )

    # WorkLogs (FKs to Issue/Task) --------------------------------
    WorkLog.create(
        issue=issue1,
        task=task1,
        agent='agent:claude-code',
        timestamp_utc=now - timedelta(hours=4),
        activity='code',
        summary='Created migration and models for password reset',
        artifacts=json.dumps([
            {'type': 'commit', 'sha': 'a1b2c3d4',
             'subject': '[pm PN-202509-001] feat: add password reset models',
             'branch': 'feat/PN-202509-001-user-can-reset-password'},
            {'type': 'file', 'path': 'backend/migrations/0002_password_reset.py'}
        ]),
        context=json.dumps({})
    )

    WorkLog.create(
        issue=issue1,
        task=task1,
        agent='agent:claude-code',
        timestamp_utc=now - timedelta(hours=3),
        activity='test',
        summary='Added comprehensive tests for password reset functionality',
        artifacts=json.dumps([
            {'type': 'commit', 'sha': 'e5f6g7h8',
             'subject': '[pm PN-202509-001] test: add password reset tests',
             'branch': 'feat/PN-202509-001-user-can-reset-password'},
            {'type': 'file', 'path': 'backend/tests/test_password_reset.py'}
        ]),
        context=json.dumps({})
    )

    WorkLog.create(
        issue=issue2,
        task=task3,
        agent='agent:claude-code',
        timestamp_utc=now - timedelta(hours=1),
        activity='refactor',
        summary='Refactored validation error handling for better UX',
        artifacts=json.dumps([
            {'type': 'commit', 'sha': 'i9j0k1l2',
             'subject': '[pm PN-202509-002] refactor: improve validation errors',
             'branch': 'fix/PN-202509-002-login-validation-errors'},
            {'type': 'file', 'path': 'frontend/src/components/ValidationError.tsx'}
        ]),
        context=json.dumps({})
    )

    WorkLog.create(
        issue=issue4,
        task=None,  # Can be None for issue-level worklogs
        agent='agent:claude-code',
        timestamp_utc=now - timedelta(hours=2),
        activity='plan',
        summary='Analyzed conversation memory requirements and designed architecture',
        artifacts=json.dumps([{'type': 'file', 'path': 'docs/conversation-memory-design.md'}]),
        context=json.dumps({})
    )

    print("✅ Mock data created successfully!")
    print(f"📊 Projects: {Project.select().count()}")
    print(f"🎫 Issues:   {Issue.select().count()}")
    print(f"📋 Tasks:    {Task.select().count()}")
    print(f"📝 WorkLogs: {WorkLog.select().count()}")

def init_database():
    """Initialize the database with tables and mock data."""
    init_db()
    # Create tables (safe=True avoids errors if they exist)
    db.create_tables([Project, Issue, Task, WorkLog], safe=True)

    if Project.select().count() == 0:
        create_mock_data()
    else:
        print("📊 Database already contains data")

if __name__ == '__main__':
    try:
        init_database()
    finally:
        close_db()
```

### src/jira_lite/models.py
```
import json
import uuid
from datetime import datetime
from peewee import *
from pathlib import Path

# SQLite database
DATABASE_PATH = Path(__file__).parent.parent.parent / 'data' / 'jira_lite.db'
DATABASE_PATH.parent.mkdir(exist_ok=True)
db = SqliteDatabase(str(DATABASE_PATH))

class BaseModel(Model):
    """Base model with common functionality"""
    class Meta:
        database = db

    def to_dict(self):
        """Convert model to dictionary for JSON serialization"""
        data = {}
        for field in self._meta.sorted_fields:
            value = getattr(self, field.name)
            if isinstance(value, datetime):
                data[field.name] = value.isoformat() + 'Z'
            elif hasattr(value, 'to_dict'):
                data[field.name] = value.to_dict()
            elif hasattr(value, 'id'):
                data[field.name] = value.id
            else:
                data[field.name] = value
        return data

class Project(BaseModel):
    """Project model with clean Django-style relationships"""
    project_id = CharField(unique=True, index=True, max_length=64)
    project_slug = CharField(index=True, max_length=100)
    absolute_path = CharField(max_length=500)
    metadata = TextField(null=True)  # JSON string for submodules, vcs, mcp config
    created_utc = DateTimeField(default=datetime.utcnow, index=True)
    updated_utc = DateTimeField(default=datetime.utcnow)

    @property
    def submodules(self):
        """Get submodules from metadata JSON"""
        if not self.metadata:
            return []
        try:
            data = json.loads(self.metadata)
            return data.get('submodules', [])
        except (json.JSONDecodeError, TypeError):
            return []

    @property
    def vcs(self):
        """Get VCS info from metadata JSON"""
        if not self.metadata:
            return {}
        try:
            data = json.loads(self.metadata)
            return data.get('vcs', {})
        except (json.JSONDecodeError, TypeError):
            return {}

    @property
    def mcp(self):
        """Get MCP config from metadata JSON"""
        if not self.metadata:
            return {}
        try:
            data = json.loads(self.metadata)
            return data.get('mcp', {})
        except (json.JSONDecodeError, TypeError):
            return {}

    def save(self, *args, **kwargs):
        self.updated_utc = datetime.utcnow()
        return super().save(*args, **kwargs)

    def to_dict(self):
        """Enhanced to_dict with metadata properties"""
        data = super().to_dict()
        data.update({
            'submodules': self.submodules,
            'vcs': self.vcs,
            'mcp': self.mcp
        })
        return data

class Issue(BaseModel):
    """Issue model with rich LLM content as JSON"""
    project = ForeignKeyField(Project, backref='issues', on_delete='CASCADE')
    key = CharField(unique=True, index=True, max_length=50)
    title = CharField(index=True, max_length=200)
    type = CharField(index=True, max_length=20)  # feature, bug, refactor, chore, spike
    status = CharField(index=True, max_length=20)  # proposed, in_progress, review, done, canceled, blocked
    priority = CharField(index=True, max_length=10)  # P1, P2, P3, P4, P5
    module = CharField(null=True, index=True, max_length=100)
    owner = CharField(null=True, index=True, max_length=100)
    external_id = CharField(null=True, index=True, max_length=100)

    # Rich LLM content as JSON strings
    specification = TextField(null=True)     # problem_statement, technical_approach, acceptance_criteria
    planning = TextField(null=True)          # dependencies, risks, stakeholders, milestones
    implementation = TextField(null=True)    # tasks, branch, commits, artifacts
    communication = TextField(null=True)     # updates, comments, notifications
    analytics = TextField(null=True)         # time_tracking, velocity, estimates

    created_utc = DateTimeField(default=datetime.utcnow, index=True)
    updated_utc = DateTimeField(default=datetime.utcnow, index=True)

    # Convenient property accessors for JSON fields
    @property
    def description(self):
        """Get description from specification JSON"""
        spec = self._get_json_field('specification')
        return spec.get('description', '')

    @property
    def acceptance(self):
        """Get acceptance criteria from specification JSON"""
        spec = self._get_json_field('specification')
        return spec.get('acceptance_criteria', [])

    @property
    def acceptance_criteria(self):
        """Alias for acceptance"""
        return self.acceptance

    @property
    def dependencies(self):
        """Get dependencies from planning JSON"""
        plan = self._get_json_field('planning')
        return plan.get('dependencies', [])

    @property
    def stakeholders(self):
        """Get stakeholders from planning JSON"""
        plan = self._get_json_field('planning')
        return plan.get('stakeholders', [])

    @property
    def estimated_effort(self):
        """Get estimated effort from planning JSON"""
        plan = self._get_json_field('planning')
        return plan.get('estimated_effort', '')

    @property
    def complexity(self):
        """Get complexity from planning JSON"""
        plan = self._get_json_field('planning')
        return plan.get('complexity', 'Medium')

    @property
    def branch_hint(self):
        """Get branch hint from implementation JSON"""
        impl = self._get_json_field('implementation')
        return impl.get('branch_hint', '')

    @property
    def commit_preamble(self):
        """Get commit preamble from implementation JSON"""
        impl = self._get_json_field('implementation')
        return impl.get('commit_preamble', '')

    @property
    def commit_trailer(self):
        """Get commit trailer from implementation JSON"""
        impl = self._get_json_field('implementation')
        return impl.get('commit_trailer', '')

    @property
    def links(self):
        """Get links from implementation JSON"""
        impl = self._get_json_field('implementation')
        return impl.get('links', {})

    def _get_json_field(self, field_name):
        """Helper to safely parse JSON fields"""
        field_value = getattr(self, field_name)
        if not field_value:
            return {}
        try:
            return json.loads(field_value)
        except (json.JSONDecodeError, TypeError):
            return {}

    def save(self, *args, **kwargs):
        self.updated_utc = datetime.utcnow()
        return super().save(*args, **kwargs)

    def to_dict(self):
        """Enhanced to_dict with JSON properties"""
        data = super().to_dict()
        data.update({
            'description': self.description,
            'acceptance': self.acceptance,
            'dependencies': self.dependencies,
            'stakeholders': self.stakeholders,
            'estimated_effort': self.estimated_effort,
            'complexity': self.complexity,
            'branch_hint': self.branch_hint,
            'commit_preamble': self.commit_preamble,
            'commit_trailer': self.commit_trailer,
            'links': self.links
        })
        return data

class Task(BaseModel):
    """Task model for issue breakdown"""
    issue = ForeignKeyField(Issue, backref='tasks', on_delete='CASCADE')
    task_id = CharField(unique=True, index=True, max_length=100)
    title = CharField(max_length=200)
    status = CharField(index=True, max_length=20)  # todo, doing, blocked, review, done
    assignee = CharField(null=True, index=True, max_length=100)
    details = TextField(null=True)  # JSON string for checklist, notes, time estimates
    created_utc = DateTimeField(default=datetime.utcnow, index=True)
    updated_utc = DateTimeField(default=datetime.utcnow, index=True)

    @property
    def checklist(self):
        """Get checklist from details JSON"""
        details = self._get_json_field('details')
        return details.get('checklist', [])

    @property
    def notes(self):
        """Get notes from details JSON"""
        details = self._get_json_field('details')
        return details.get('notes', '')

    @property
    def time_estimate(self):
        """Get time estimate from details JSON"""
        details = self._get_json_field('details')
        return details.get('time_estimate', '')

    def _get_json_field(self, field_name):
        """Helper to safely parse JSON fields"""
        field_value = getattr(self, field_name)
        if not field_value:
            return {}
        try:
            return json.loads(field_value)
        except (json.JSONDecodeError, TypeError):
            return {}

    def save(self, *args, **kwargs):
        self.updated_utc = datetime.utcnow()
        return super().save(*args, **kwargs)

    def to_dict(self):
        """Enhanced to_dict with JSON properties"""
        data = super().to_dict()
        data.update({
            'checklist': self.checklist,
            'notes': self.notes,
            'time_estimate': self.time_estimate
        })
        return data

class WorkLog(BaseModel):
    """WorkLog model for tracking development activity"""
    issue = ForeignKeyField(Issue, backref='worklogs', on_delete='CASCADE')
    task = ForeignKeyField(Task, backref='worklogs', on_delete='SET NULL', null=True)
    agent = CharField(index=True, max_length=100)
    timestamp_utc = DateTimeField(default=datetime.utcnow, index=True)
    activity = CharField(index=True, max_length=50)  # code, design, review, test, planning, blocked
    summary = TextField()
    artifacts = TextField(null=True)  # JSON string for commits, files, links
    context = TextField(null=True)    # JSON string for blockers, decisions, learnings

    @property
    def artifacts_list(self):
        """Get artifacts list from JSON"""
        return self._get_json_list('artifacts')

    @property
    def context_data(self):
        """Get context data from JSON"""
        return self._get_json_dict('context')

    def _get_json_list(self, field_name):
        """Helper to safely parse JSON list fields"""
        val = getattr(self, field_name)
        if not val:
            return []
        try:
            data = json.loads(val)
            return data if isinstance(data, list) else []
        except Exception:
            return []

    def _get_json_dict(self, field_name):
        """Helper to safely parse JSON dict fields"""
        val = getattr(self, field_name)
        if not val:
            return {}
        try:
            data = json.loads(val)
            return data if isinstance(data, dict) else {}
        except Exception:
            return {}

    def to_dict(self):
        """Enhanced to_dict with JSON properties"""
        data = super().to_dict()
        data.update({
            'artifacts': self.artifacts_list,
            'context': self.context_data
        })
        return data

# Database initialization
def init_db():
    """Initialize database and create tables"""
    db.connect(reuse_if_open=True)
    db.create_tables([Project, Issue, Task, WorkLog], safe=True)
    return db

def close_db():
    """Close database connection"""
    if not db.is_closed():
        db.close()

# Context manager for database operations
class DatabaseManager:
    def __enter__(self):
        init_db()
        return db

    def __exit__(self, exc_type, exc_val, exc_tb):
        close_db()

# Auto-initialize when imported
if __name__ != '__main__':
    init_db()
```

### src/jira_lite/repositories.py
```
import json
from datetime import datetime
from typing import List, Optional, Dict, Any
from peewee import DoesNotExist, IntegrityError

from .models import Project, Issue, Task, WorkLog, db

class ProjectRepository:
    """Clean repository interface for Project operations"""

    @staticmethod
    def get_all() -> List[Project]:
        """Get all projects ordered by slug"""
        return list(Project.select().order_by(Project.project_slug))

    @staticmethod
    def find_by_id(project_id: str) -> Optional[Project]:
        """Find project by project_id"""
        try:
            return Project.get(Project.project_id == project_id)
        except DoesNotExist:
            return None

    @staticmethod
    def find_by_slug(slug: str) -> Optional[Project]:
        """Find project by slug"""
        try:
            return Project.get(Project.project_slug == slug)
        except DoesNotExist:
            return None

    @staticmethod
    def create_or_update(project_data: Dict[str, Any]) -> Project:
        """Create new project or update existing"""
        try:
            # Try to find existing project
            project = Project.get(Project.project_id == project_data['project_id'])

            # Update existing project
            project.project_slug = project_data.get('project_slug', project.project_slug)
            project.absolute_path = project_data.get('absolute_path', project.absolute_path)

            # Update metadata
            metadata = {
                'submodules': project_data.get('submodules', []),
                'vcs': project_data.get('vcs', {}),
                'mcp': project_data.get('mcp', {})
            }
            project.metadata = json.dumps(metadata)
            project.save()

        except DoesNotExist:
            # Create new project
            metadata = {
                'submodules': project_data.get('submodules', []),
                'vcs': project_data.get('vcs', {}),
                'mcp': project_data.get('mcp', {})
            }

            project = Project.create(
                project_id=project_data['project_id'],
                project_slug=project_data['project_slug'],
                absolute_path=project_data['absolute_path'],
                metadata=json.dumps(metadata)
            )

        return project

class IssueRepository:
    """Clean repository interface for Issue operations"""

    @staticmethod
    def find_by_key(key: str) -> Optional[Issue]:
        """Find issue by unique key"""
        try:
            return Issue.get(Issue.key == key)
        except DoesNotExist:
            return None

    @staticmethod
    def find_by_project(project_id: str, **filters) -> List[Issue]:
        """Find issues by project with optional filtering"""
        query = (Issue
                .select()
                .join(Project)
                .where(Project.project_id == project_id))

        # Apply filters
        if filters.get('status'):
            query = query.where(Issue.status == filters['status'])
        if filters.get('priority'):
            query = query.where(Issue.priority == filters['priority'])
        if filters.get('module'):
            query = query.where(Issue.module == filters['module'])
        if filters.get('owner'):
            query = query.where(Issue.owner == filters['owner'])
        if filters.get('type'):
            query = query.where(Issue.type == filters['type'])

        return list(query.order_by(Issue.updated_utc.desc()))

    @staticmethod
    def search_text(search_query: str, project_id: str = None) -> List[Issue]:
        """Full-text search across issue content"""
        # Build search conditions
        search_conditions = (
            Issue.title.contains(search_query) |
            Issue.specification.contains(search_query) |
            Issue.planning.contains(search_query) |
            Issue.implementation.contains(search_query)
        )

        query = Issue.select().where(search_conditions)

        if project_id:
            query = query.join(Project).where(Project.project_id == project_id)

        return list(query.order_by(Issue.updated_utc.desc()))

    @staticmethod
    def get_my_queue(owner: str, limit: int = 20) -> List[Issue]:
        """Get prioritized work queue for specific owner"""
        return list(
            Issue.select()
            .where(
                (Issue.owner == owner) &
                (Issue.status.in_(['proposed', 'in_progress']))
            )
            .order_by(
                Issue.priority.asc(),  # P1 first
                Issue.updated_utc.desc()
            )
            .limit(limit)
        )

    @staticmethod
    def get_blocked_issues(project_id: str = None) -> List[Issue]:
        """Get all blocked issues"""
        query = Issue.select().where(Issue.status == 'blocked')

        if project_id:
            query = query.join(Project).where(Project.project_id == project_id)

        return list(query.order_by(Issue.updated_utc.desc()))

    @staticmethod
    def get_dependencies(issue_key: str) -> Dict[str, List[str]]:
        """Get issue dependencies and things it blocks"""
        issue = IssueRepository.find_by_key(issue_key)
        if not issue:
            return {"depends_on": [], "blocks": []}

        depends_on = issue.dependencies

        # Find issues that depend on this one
        blocks = []
        for other_issue in Issue.select():
            if issue_key in other_issue.dependencies:
                blocks.append(other_issue.key)

        return {
            "depends_on": depends_on,
            "blocks": blocks
        }

    @staticmethod
    def create_or_update(issue_data: Dict[str, Any]) -> Issue:
        """Create new issue or update existing by key"""

        # Prepare structured data
        structured_fields = {
            'key': issue_data['key'],
            'title': issue_data['title'],
            'type': issue_data['type'],
            'status': issue_data.get('status', 'proposed'),
            'priority': issue_data.get('priority', 'P3'),
            'module': issue_data.get('module'),
            'owner': issue_data.get('owner'),
            'external_id': issue_data.get('external_id')
        }

        # Prepare JSON fields
        specification = {
            'description': issue_data.get('description', ''),
            'acceptance_criteria': issue_data.get('acceptance', []),
            'technical_approach': issue_data.get('technical_approach', ''),
            'business_requirements': issue_data.get('business_requirements', [])
        }

        planning = {
            'dependencies': issue_data.get('dependencies', []),
            'stakeholders': issue_data.get('stakeholders', []),
            'estimated_effort': issue_data.get('estimated_effort', ''),
            'complexity': issue_data.get('complexity', 'Medium'),
            'risks': issue_data.get('risks', [])
        }

        implementation = {
            'branch_hint': issue_data.get('branch_hint', ''),
            'commit_preamble': issue_data.get('commit_preamble', ''),
            'commit_trailer': issue_data.get('commit_trailer', ''),
            'links': issue_data.get('links', {}),
            'artifacts': issue_data.get('artifacts', [])
        }

        try:
            # Find existing issue
            issue = Issue.get(Issue.key == issue_data['key'])

            # Update existing
            for key, value in structured_fields.items():
                if value is not None:
                    setattr(issue, key, value)

            issue.specification = json.dumps(specification)
            issue.planning = json.dumps(planning)
            issue.implementation = json.dumps(implementation)
            issue.save()

        except DoesNotExist:
            # Create new issue - need to find project first
            project = None
            if 'project_id' in issue_data:
                project = ProjectRepository.find_by_id(issue_data['project_id'])

            if not project:
                raise ValueError(f"Project not found: {issue_data.get('project_id')}")

            issue = Issue.create(
                project=project,
                specification=json.dumps(specification),
                planning=json.dumps(planning),
                implementation=json.dumps(implementation),
                **structured_fields
            )

        return issue

class TaskRepository:
    """Clean repository interface for Task operations"""

    @staticmethod
    def find_by_id(task_id: str) -> Optional[Task]:
        """Find task by task_id"""
        try:
            return Task.get(Task.task_id == task_id)
        except DoesNotExist:
            return None

    @staticmethod
    def find_by_issue(issue_key: str) -> List[Task]:
        """Find all tasks for an issue"""
        return list(
            Task.select()
            .join(Issue)
            .where(Issue.key == issue_key)
            .order_by(Task.created_utc.asc())
        )

    @staticmethod
    def find_by_project(project_id: str, **filters) -> List[Task]:
        """Find tasks by project with optional filtering"""
        query = (Task
                .select()
                .join(Issue)
                .join(Project)
                .where(Project.project_id == project_id))

        if filters.get('status'):
            query = query.where(Task.status == filters['status'])
        if filters.get('assignee'):
            query = query.where(Task.assignee == filters['assignee'])

        return list(query.order_by(Task.updated_utc.desc()))

    @staticmethod
    def create_or_update(task_data: Dict[str, Any]) -> Task:
        """Create new task or update existing"""

        # Prepare details JSON
        details = {
            'checklist': task_data.get('checklist', []),
            'notes': task_data.get('notes', ''),
            'time_estimate': task_data.get('time_estimate', '')
        }

        try:
            # Find existing task
            task = Task.get(Task.task_id == task_data['task_id'])

            # Update existing
            task.title = task_data.get('title', task.title)
            task.status = task_data.get('status', task.status)
            task.assignee = task_data.get('assignee', task.assignee)
            task.details = json.dumps(details)
            task.save()

        except DoesNotExist:
            # Create new task - find issue first
            issue = IssueRepository.find_by_key(task_data['issue_key'])
            if not issue:
                raise ValueError(f"Issue not found: {task_data.get('issue_key')}")

            task = Task.create(
                issue=issue,
                task_id=task_data['task_id'],
                title=task_data['title'],
                status=task_data.get('status', 'todo'),
                assignee=task_data.get('assignee'),
                details=json.dumps(details)
            )

        return task

class WorkLogRepository:
    """Clean repository interface for WorkLog operations"""

    @staticmethod
    def find_by_issue(issue_key: str, limit: int = 50) -> List[WorkLog]:
        """Find worklogs for an issue"""
        return list(
            WorkLog.select()
            .join(Issue)
            .where(Issue.key == issue_key)
            .order_by(WorkLog.timestamp_utc.desc())
            .limit(limit)
        )

    @staticmethod
    def find_by_project(project_id: str, **filters) -> List[WorkLog]:
        """Find worklogs by project with optional filtering"""
        query = (WorkLog
                .select()
                .join(Issue)
                .join(Project)
                .where(Project.project_id == project_id))

        if filters.get('agent'):
            query = query.where(WorkLog.agent == filters['agent'])
        if filters.get('activity'):
            query = query.where(WorkLog.activity == filters['activity'])
        if filters.get('issue_key'):
            query = query.where(Issue.key == filters['issue_key'])

        limit = filters.get('limit', 100)
        return list(query.order_by(WorkLog.timestamp_utc.desc()).limit(limit))

    @staticmethod
    def add_entry(worklog_data: Dict[str, Any]) -> WorkLog:
        """Add new worklog entry"""

        # Find issue
        issue = IssueRepository.find_by_key(worklog_data['issue_key'])
        if not issue:
            raise ValueError(f"Issue not found: {worklog_data.get('issue_key')}")

        # Find task (optional)
        task = None
        if worklog_data.get('task_id'):
            task = TaskRepository.find_by_id(worklog_data['task_id'])

        # Prepare artifacts and context
        artifacts = json.dumps(worklog_data.get('artifacts', []))
        context = json.dumps(worklog_data.get('context', {}))

        worklog = WorkLog.create(
            issue=issue,
            task=task,
            agent=worklog_data['agent'],
            activity=worklog_data['activity'],
            summary=worklog_data['summary'],
            artifacts=artifacts,
            context=context,
            timestamp_utc=worklog_data.get('timestamp_utc', datetime.utcnow())
        )

        return worklog

    @staticmethod
    def get_recent_activity(project_id: str = None, limit: int = 20) -> List[WorkLog]:
        """Get recent activity across projects"""
        query = WorkLog.select().join(Issue).join(Project)

        if project_id:
            query = query.where(Project.project_id == project_id)

        return list(query.order_by(WorkLog.timestamp_utc.desc()).limit(limit))

class PMService:
    """High-level service combining repositories for complex operations"""

    def __init__(self):
        self.projects = ProjectRepository()
        self.issues = IssueRepository()
        self.tasks = TaskRepository()
        self.worklogs = WorkLogRepository()

    def get_project_dashboard(self, project_id: str) -> Dict[str, Any]:
        """Get comprehensive project dashboard data"""
        project = self.projects.find_by_id(project_id)
        if not project:
            raise ValueError(f"Project not found: {project_id}")

        issues = self.issues.find_by_project(project_id)
        recent_worklogs = self.worklogs.find_by_project(project_id, limit=10)

        # Calculate stats
        issue_stats = {}
        for issue in issues:
            status = issue.status
            issue_stats[status] = issue_stats.get(status, 0) + 1

        return {
            'project': project.to_dict(),
            'issues': [issue.to_dict() for issue in issues],
            'recent_worklogs': [wl.to_dict() for wl in recent_worklogs],
            'stats': {
                'issue_counts': issue_stats,
                'total_issues': len(issues)
            }
        }

    def get_issue_with_context(self, issue_key: str) -> Dict[str, Any]:
        """Get issue with all related tasks and worklogs"""
        issue = self.issues.find_by_key(issue_key)
        if not issue:
            raise ValueError(f"Issue not found: {issue_key}")

        tasks = self.tasks.find_by_issue(issue_key)
        worklogs = self.worklogs.find_by_issue(issue_key)
        dependencies = self.issues.get_dependencies(issue_key)

        return {
            'issue': issue.to_dict(),
            'project': issue.project.to_dict(),
            'tasks': [task.to_dict() for task in tasks],
            'worklogs': [wl.to_dict() for wl in worklogs],
            'dependencies': dependencies
        }

    def create_comprehensive_issue(self, project_id: str, issue_data: Dict[str, Any]) -> Issue:
        """Create issue with full LLM-generated content"""

        # Generate issue key if not provided
        if 'key' not in issue_data:
            project = self.projects.find_by_id(project_id)
            if not project:
                raise ValueError(f"Project not found: {project_id}")

            # Get existing issue count for this project
            existing_count = Issue.select().join(Project).where(Project.project_id == project_id).count()
            project_prefix = project.project_slug.upper().replace('-', '')[:4]
            issue_data['key'] = f"{project_prefix}-{existing_count + 1:03d}"

        # Auto-generate git integration fields
        if 'branch_hint' not in issue_data:
            title_slug = issue_data['title'].lower().replace(' ', '-').replace('_', '-')[:40]
            issue_data['branch_hint'] = f"{issue_data['type']}/{issue_data['key'].lower()}-{title_slug}"

        if 'commit_preamble' not in issue_data:
            issue_data['commit_preamble'] = f"[pm {issue_data['key']}]"

        if 'commit_trailer' not in issue_data:
            issue_data['commit_trailer'] = f"PM: {issue_data['key']}"

        # Add project_id for repository method
        issue_data['project_id'] = project_id

        return self.issues.create_or_update(issue_data)

    def update_issue_status(self, issue_key: str, new_status: str, notes: str = '', notify: bool = True) -> Issue:
        """Update issue status with proper workflow validation"""
        issue = self.issues.find_by_key(issue_key)
        if not issue:
            raise ValueError(f"Issue not found: {issue_key}")

        old_status = issue.status

        # Update status
        issue.status = new_status
        issue.save()

        # Log the status change
        self.worklogs.add_entry({
            'issue_key': issue_key,
            'agent': 'system:status-change',
            'activity': 'status_change',
            'summary': f"Status changed from {old_status} to {new_status}",
            'context': {
                'old_status': old_status,
                'new_status': new_status,
                'notes': notes,
                'notify_stakeholders': notify
            }
        })

        return issue

    def log_development_work(self, issue_key: str, agent: str, activity: str,
                           summary: str, artifacts: List[Dict] = None,
                           context: Dict = None) -> WorkLog:
        """Log development work with rich context"""

        worklog_data = {
            'issue_key': issue_key,
            'agent': agent,
            'activity': activity,
            'summary': summary,
            'artifacts': artifacts or [],
            'context': context or {}
        }

        return self.worklogs.add_entry(worklog_data)

# Global service instance
pm_service = PMService()
```

### src/jira_lite/storage.py
```
import json
import os
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Optional
import uuid

class JSONStorage:
    def __init__(self, data_dir: str = "data"):
        self.data_dir = Path(data_dir)
        self.data_dir.mkdir(exist_ok=True)

        self.projects_file = self.data_dir / "projects.json"
        self.issues_file = self.data_dir / "issues.json"
        self.tasks_file = self.data_dir / "tasks.json"
        self.worklogs_file = self.data_dir / "worklogs.json"

        # Initialize files if they don't exist
        self._ensure_file_exists(self.projects_file, [])
        self._ensure_file_exists(self.issues_file, [])
        self._ensure_file_exists(self.tasks_file, [])
        self._ensure_file_exists(self.worklogs_file, [])

    def _ensure_file_exists(self, file_path: Path, default_content):
        if not file_path.exists():
            with open(file_path, 'w') as f:
                json.dump(default_content, f, indent=2)

    def _load_json(self, file_path: Path) -> List[Dict]:
        try:
            with open(file_path, 'r') as f:
                return json.load(f)
        except (FileNotFoundError, json.JSONDecodeError):
            return []

    def _save_json(self, file_path: Path, data: List[Dict]):
        with open(file_path, 'w') as f:
            json.dump(data, f, indent=2, default=str)

    # Projects
    def get_projects(self) -> List[Dict]:
        return self._load_json(self.projects_file)

    def get_project_by_id(self, project_id: str) -> Optional[Dict]:
        projects = self.get_projects()
        return next((p for p in projects if p['project_id'] == project_id), None)

    def add_project(self, project_data: Dict) -> Dict:
        projects = self.get_projects()

        # Check if project already exists
        existing = next((p for p in projects if p['project_id'] == project_data['project_id']), None)
        if existing:
            return existing

        # Add timestamp if not present
        if 'created_utc' not in project_data:
            project_data['created_utc'] = datetime.utcnow().isoformat() + 'Z'

        projects.append(project_data)
        self._save_json(self.projects_file, projects)
        return project_data

    # Issues
    def get_issues(self, project_id: str = None, status: str = None, issue_type: str = None,
                   module: str = None, owner: str = None) -> List[Dict]:
        issues = self._load_json(self.issues_file)

        if project_id:
            issues = [i for i in issues if i.get('project_id') == project_id]
        if status:
            issues = [i for i in issues if i.get('status') == status]
        if issue_type:
            issues = [i for i in issues if i.get('type') == issue_type]
        if module:
            issues = [i for i in issues if i.get('module') == module]
        if owner:
            issues = [i for i in issues if i.get('owner') == owner]

        return issues

    def get_issue_by_key(self, key: str) -> Optional[Dict]:
        issues = self._load_json(self.issues_file)
        return next((i for i in issues if i['key'] == key), None)

    def upsert_issue(self, issue_data: Dict) -> Dict:
        issues = self._load_json(self.issues_file)

        # Find existing issue by key or external_id
        existing_index = -1
        if 'key' in issue_data:
            for i, issue in enumerate(issues):
                if issue.get('key') == issue_data['key'] and issue.get('project_id') == issue_data.get('project_id'):
                    existing_index = i
                    break
        elif 'external_id' in issue_data:
            for i, issue in enumerate(issues):
                if issue.get('external_id') == issue_data['external_id']:
                    existing_index = i
                    break

        # Add timestamps
        now = datetime.utcnow().isoformat() + 'Z'
        if existing_index >= 0:
            # Update existing
            issue_data['updated_utc'] = now
            if 'created_utc' not in issue_data:
                issue_data['created_utc'] = issues[existing_index].get('created_utc', now)
            issues[existing_index] = issue_data
        else:
            # Create new
            issue_data['created_utc'] = now
            issue_data['updated_utc'] = now
            issues.append(issue_data)

        self._save_json(self.issues_file, issues)
        return issue_data

    # Tasks
    def get_tasks(self, project_id: str = None, issue_key: str = None, status: str = None) -> List[Dict]:
        tasks = self._load_json(self.tasks_file)

        if project_id:
            tasks = [t for t in tasks if t.get('project_id') == project_id]
        if issue_key:
            tasks = [t for t in tasks if t.get('issue_key') == issue_key]
        if status:
            tasks = [t for t in tasks if t.get('status') == status]

        return tasks

    def upsert_task(self, task_data: Dict) -> Dict:
        tasks = self._load_json(self.tasks_file)

        # Find existing task
        existing_index = -1
        for i, task in enumerate(tasks):
            if task.get('task_id') == task_data.get('task_id'):
                existing_index = i
                break

        # Add timestamps
        now = datetime.utcnow().isoformat() + 'Z'
        if existing_index >= 0:
            # Update existing
            task_data['updated_utc'] = now
            if 'created_utc' not in task_data:
                task_data['created_utc'] = tasks[existing_index].get('created_utc', now)
            tasks[existing_index] = task_data
        else:
            # Create new
            task_data['created_utc'] = now
            task_data['updated_utc'] = now
            tasks.append(task_data)

        self._save_json(self.tasks_file, tasks)
        return task_data

    # WorkLogs
    def get_worklogs(self, project_id: str = None, issue_key: str = None, task_id: str = None,
                     agent: str = None, activity: str = None) -> List[Dict]:
        worklogs = self._load_json(self.worklogs_file)

        if project_id:
            worklogs = [w for w in worklogs if w.get('project_id') == project_id]
        if issue_key:
            worklogs = [w for w in worklogs if w.get('issue_key') == issue_key]
        if task_id:
            worklogs = [w for w in worklogs if w.get('task_id') == task_id]
        if agent:
            worklogs = [w for w in worklogs if w.get('agent') == agent]
        if activity:
            worklogs = [w for w in worklogs if w.get('activity') == activity]

        # Sort by timestamp (most recent first)
        worklogs.sort(key=lambda x: x.get('timestamp_utc', ''), reverse=True)
        return worklogs

    def add_worklog(self, worklog_data: Dict) -> Dict:
        worklogs = self._load_json(self.worklogs_file)

        # Add timestamp if not present
        if 'timestamp_utc' not in worklog_data:
            worklog_data['timestamp_utc'] = datetime.utcnow().isoformat() + 'Z'

        # Add unique ID
        worklog_data['id'] = str(uuid.uuid4())

        worklogs.append(worklog_data)
        self._save_json(self.worklogs_file, worklogs)
        return worklog_data
```

### src/jira_lite/utils.py
```
import markdown
import bleach
from datetime import datetime
from markupsafe import Markup

# Allowed HTML tags for markdown rendering
ALLOWED_TAGS = [
    'h1', 'h2', 'h3', 'h4', 'h5', 'h6',
    'p', 'br', 'strong', 'em', 'u', 'del', 'ins',
    'ul', 'ol', 'li', 'blockquote', 'code', 'pre',
    'a', 'img', 'table', 'thead', 'tbody', 'tr', 'th', 'td',
    'hr', 'div', 'span'
]

ALLOWED_ATTRIBUTES = {
    'a': ['href', 'title'],
    'img': ['src', 'alt', 'title', 'width', 'height'],
    'code': ['class'],
    'pre': ['class'],
    'div': ['class'],
    'span': ['class']
}

def render_markdown(text):
    """Convert markdown text to safe HTML."""
    if not text:
        return ""

    # Convert markdown to HTML
    html = markdown.markdown(
        text,
        extensions=[
            'markdown.extensions.fenced_code',
            'markdown.extensions.tables',
            'markdown.extensions.toc',
            'markdown.extensions.nl2br'
        ]
    )

    # Sanitize HTML to prevent XSS
    clean_html = bleach.clean(
        html,
        tags=ALLOWED_TAGS,
        attributes=ALLOWED_ATTRIBUTES,
        strip=True
    )

    return Markup(clean_html)

def truncate_text(text, length=150):
    """Truncate text to specified length with ellipsis."""
    if not text:
        return ""

    # Remove markdown formatting for display
    plain_text = bleach.clean(text, tags=[], strip=True)

    if len(plain_text) <= length:
        return plain_text

    return plain_text[:length].rsplit(' ', 1)[0] + '...'

def extract_summary(description):
    """Extract a summary from the description markdown."""
    if not description:
        return "No description available."

    lines = description.split('\n')

    # Find first meaningful paragraph (skip headers and empty lines)
    for line in lines:
        line = line.strip()
        if line and not line.startswith('#') and not line.startswith('```'):
            return truncate_text(line, 200)

    return "No description available."

def format_date(date_obj, format='%Y-%m-%d'):
    """Format date object or string safely"""
    if not date_obj:
        return 'N/A'

    if isinstance(date_obj, str):
        # Handle ISO string format
        try:
            if date_obj.endswith('Z'):
                date_obj = date_obj[:-1]  # Remove Z
            dt = datetime.fromisoformat(date_obj)
            return dt.strftime(format)
        except ValueError:
            return date_obj[:10] if len(date_obj) >= 10 else date_obj

    if isinstance(date_obj, datetime):
        return date_obj.strftime(format)

    return str(date_obj)

def format_datetime(date_obj, format='%Y-%m-%d %H:%M'):
    """Format datetime object or string safely"""
    return format_date(date_obj, format)
```

### src/tools/__init__.py
```

```

### src/__init__.py
```

```

### docker-compose.yml
```
version: '3.8'

services:
  jira-lite:
    build: .
    ports:
      - "1929:1929"
    environment:
      - FLASK_ENV=development
      - FLASK_DEBUG=1
    volumes:
      # Mount source code for development
      - ./src:/app/src
      - ./docs:/app/docs
      # Persist SQLite database
      - jira_lite_data:/app/data
      # Mount project data for MCP integration
      - ./test-projects:/app/projects:ro
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:1929/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  # Optional: Add a reverse proxy for production
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
    depends_on:
      - jira-lite
    profiles:
      - production

volumes:
  jira_lite_data:
    driver: local

networks:
  default:
    name: llm-pm-network
```

### Dockerfile
```
# LLM-Native Project Management - Jira-lite
FROM python:3.11-slim

# Set working directory
WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    gcc \
    && rm -rf /var/lib/apt/lists/*

# Copy requirements first for better Docker layer caching
COPY requirements.txt .

# Install Python dependencies
RUN pip install --no-cache-dir -r requirements.txt

# Copy source code
COPY src/ ./src/
COPY Makefile .
COPY docs/ ./docs/

# Create data directory for SQLite database
RUN mkdir -p /app/data

# Create non-root user for security
RUN groupadd -r jira_lite && useradd -r -g jira_lite jira_lite
RUN chown -R jira_lite:jira_lite /app
USER jira_lite

# Expose port
EXPOSE 1929

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:1929/api/health || exit 1

# Default command
CMD ["python", "-m", "src.jira_lite.app", "--port", "1929", "--host", "0.0.0.0", "--auto"]
```

### Makefile
```
PORT ?= 1929
PYTHON := python3
VENV := venv
VENV_BIN := $(VENV)/bin
MCP_VENV := mcp/venv
MCP_VENV_BIN := $(MCP_VENV)/bin

.PHONY: help bootstrap bootstrap-mcp init register jl-run-auto jl-init-db migrate-to-db mcp-install mcp-run mcp-validate mcp-claude-config docker-build docker-run docker-stop clean test

help: ## Show this help message
	@echo "Available targets:"
	@grep -E '^[a-zA-Z_-]+:.*?## .*$$' $(MAKEFILE_LIST) | awk 'BEGIN {FS = ":.*?## "}; {printf "  %-20s %s\n", $$1, $$2}'

bootstrap: ## Set up Python virtual environment and install dependencies
	$(PYTHON) -m venv $(VENV)
	$(VENV_BIN)/pip install --upgrade pip
	$(VENV_BIN)/pip install -r requirements.txt
	@echo "✅ Virtual environment created and dependencies installed"

jl-run-auto: bootstrap ## Start Jira-lite server with auto port detection
	@echo "🚀 Starting Jira-lite server..."
	$(VENV_BIN)/python -m src.jira_lite.app --port $(PORT) --auto

jl-init-db: bootstrap ## Initialize JSON files with mock data
	@echo "🗄️  Initializing JSON files with mock data..."
	$(VENV_BIN)/python -m src.jira_lite.mock_data

# MCP Server targets
bootstrap-mcp: ## Setup MCP server environment
	@echo "🔧 Setting up MCP server..."
	cd mcp && $(PYTHON) -m venv venv
	cd mcp && venv/bin/pip install --upgrade pip
	cd mcp && venv/bin/pip install -r requirements.txt
	@echo "✅ MCP server dependencies installed"

mcp-validate: bootstrap-mcp ## Validate MCP server configuration
	@echo "🔍 Validating MCP server..."
	cd mcp && PM_DATABASE_PATH=../data/jira_lite.db venv/bin/python src/server.py --validate-config

mcp-run: bootstrap-mcp ## Run MCP server in stdio mode
	@echo "🚀 Starting MCP server..."
	cd mcp && PM_DATABASE_PATH=../data/jira_lite.db venv/bin/python src/server.py --transport stdio

mcp-run-http: bootstrap-mcp ## Run MCP server in HTTP mode for testing
	@echo "🚀 Starting MCP server in HTTP mode..."
	cd mcp && PM_DATABASE_PATH=../data/jira_lite.db venv/bin/python src/server.py --transport http --port 8848

mcp-claude-config: ## Show Claude Desktop configuration for MCP server
	@echo "🔧 Claude Desktop MCP Server Configuration:"
	@echo ""
	@echo "Add this to your claude_desktop_config.json:"
	@echo '{'
	@echo '  "mcpServers": {'
	@echo '    "pm": {'
	@echo '      "command": "'$(shell pwd)'/mcp/venv/bin/python",'
	@echo '      "args": ["'$(shell pwd)'/mcp/src/server.py", "--transport", "stdio"],'
	@echo '      "env": {'
	@echo '        "PM_DATABASE_PATH": "'$(shell pwd)'/data/jira_lite.db"'
	@echo '      }'
	@echo '    }'
	@echo '  }'
	@echo '}'
	@echo ""
	@echo "Then restart Claude Desktop to load the PM server."

mcp-install: bootstrap-mcp mcp-validate ## Complete MCP server installation
	@echo ""
	@echo "✅ PM MCP Server installed successfully!"
	@echo ""
	@echo "Quick start:"
	@echo "  make mcp-run          # Test MCP server in stdio mode"
	@echo "  make mcp-run-http     # Test in HTTP mode (http://127.0.0.1:8848)"
	@echo "  make mcp-claude-config # Get Claude Desktop configuration"

init: bootstrap ## Create project initialization tool
	@echo "🔧 Project initialization not yet implemented"
	@echo "   Use the web UI to create projects for now"
	@echo "   Visit: http://127.0.0.1:$(PORT)"

register: bootstrap ## Register project with Jira-lite server
	@echo "📝 Project registration not yet implemented"
	@echo "   Use the web UI to register projects for now"
	@echo "   Visit: http://127.0.0.1:$(PORT)"

test: bootstrap ## Run basic functionality tests
	@echo "🧪 Testing API endpoints..."
	@$(VENV_BIN)/python -c "import requests; print('Health check:', requests.get('http://127.0.0.1:$(PORT)/api/health').json())" 2>/dev/null || echo "❌ Server not running on port $(PORT)"

clean: ## Clean up generated files and virtual environment
	rm -rf $(VENV)
	rm -rf __pycache__
	rm -rf src/__pycache__
	rm -rf src/jira_lite/__pycache__
	rm -rf src/jira_lite/api/__pycache__
	find . -name "*.pyc" -delete
	@echo "✅ Cleaned up generated files"

# Quick start targets
demo: jl-init-db jl-run-auto ## Initialize with mock data and start server

migrate-to-db: bootstrap ## Migrate JSON data to SQLite database
	@echo "🔄 Migrating JSON data to SQLite + Peewee..."
	$(VENV_BIN)/python -m src.jira_lite.migrate

# Docker targets
docker-build: ## Build Docker image
	@echo "🐳 Building Docker image..."
	docker build -t jira-lite:latest .

docker-run: docker-build ## Run application in Docker
	@echo "🚀 Starting Jira-lite in Docker..."
	docker-compose up -d

docker-stop: ## Stop Docker containers
	@echo "⏹️  Stopping Docker containers..."
	docker-compose down

docker-logs: ## View Docker logs
	docker-compose logs -f jira-lite

docker-shell: ## Get shell in running container
	docker-compose exec jira-lite /bin/bash

# Combined targets
install: bootstrap jl-init-db ## Full installation: setup venv, install deps, init DB
	@echo ""
	@echo "✅ Installation complete!"
	@echo "   Run: make jl-run-auto"
	@echo "   Then visit: http://127.0.0.1:$(PORT)"

install-db: bootstrap migrate-to-db ## Install with SQLite database migration
	@echo ""
	@echo "✅ Database installation complete!"
	@echo "   Run: make jl-run-auto"
	@echo "   Then visit: http://127.0.0.1:$(PORT)"

# Complete installation with both web UI and MCP server
install-complete: bootstrap migrate-to-db bootstrap-mcp mcp-validate ## Complete installation: Web UI + MCP server
	@echo ""
	@echo "🎉 Complete LLM-Native PM System installed!"
	@echo ""
	@echo "Web UI:"
	@echo "   make jl-run-auto     # Start at http://127.0.0.1:$(PORT)"
	@echo ""
	@echo "MCP Server:"
	@echo "   make mcp-run         # Test MCP server"
	@echo "   make mcp-claude-config # Get Claude Desktop config"
	@echo ""
	@echo "Database: $(shell pwd)/data/jira_lite.db"
	@echo "Projects: $(shell $(VENV_BIN)/python -c 'import sys; sys.path.insert(0, \"src\"); from jira_lite.repositories import ProjectRepository; print(len(ProjectRepository.get_all()))' 2>/dev/null || echo 'Check manually') found"

docker-demo: docker-run ## Complete Docker demo setup
	@echo ""
	@echo "✅ Docker demo running!"
	@echo "   Visit: http://127.0.0.1:1929"
	@echo "   API: http://127.0.0.1:1929/api"
	@echo "   Stop with: make docker-stop"

# Quick demo that starts everything
# Ultimate quickstart command
quickstart: install-complete ## 🚀 Complete setup + Claude Code integration ready
	@echo ""
	@echo "🎯 Running quickstart script..."
	$(PYTHON) scripts/quickstart.py
	@echo ""
	@echo "🌟 Starting Web UI..."
	$(VENV_BIN)/python -m src.jira_lite.app --port $(PORT) --auto

demo-full: install-complete ## Demo: Complete system with web UI and MCP server
	@echo ""
	@echo "🎯 Starting complete demo..."
	@echo "   1. Web UI will start at http://127.0.0.1:$(PORT)"
	@echo "   2. Use 'make mcp-claude-config' for Claude Desktop setup"
	@echo "   3. Test MCP tools with 'make mcp-run-http'"
	@echo ""
	$(VENV_BIN)/python -m src.jira_lite.app --port $(PORT) --auto
```

### QUICKSTART_INSTRUCTIONS.md
```
# LLM-Native PM System Setup Complete!

## 1. Claude Code MCP Integration
Run this command to add the PM server to Claude Code:

claude mcp add pm -- "/Users/juliusolsson/Desktop/Development/lazy-llms/mcp/venv/bin/python" "/Users/juliusolsson/Desktop/Development/lazy-llms/mcp/src/server.py" --transport stdio

## 2. Environment Setup (Optional)
Add this to your shell profile for permanent configuration:

export PM_DATABASE_PATH="/Users/juliusolsson/Desktop/Development/lazy-llms/data/jira_lite.db"

## 3. Web UI Access
- Dashboard: http://127.0.0.1:1928
- Create issues, manage projects, view analytics

## 4. Available MCP Tools
- pm_docs                 # Get system documentation
- pm_status               # Project health overview
- pm_list_issues          # List and filter issues
- pm_create_issue         # Create rich issues with specs
- pm_start_work           # Begin work with git branch
- pm_log_work            # Track development activity
- pm_commit              # Commit with PM trailers
- pm_my_queue            # Get prioritized work queue
- pm_daily_standup       # Generate standup reports

## 5. Typical Workflow
pm_docs                  # Understand the system
pm_status                # Get project overview
pm_my_queue             # Get your work queue
pm_create_issue         # Create new work
pm_start_work           # Begin implementation
pm_log_work             # Track progress
pm_commit               # Save changes

Database: /Users/juliusolsson/Desktop/Development/lazy-llms/data/jira_lite.db
Projects: 4 found with 13 issues, 7 tasks, 16 worklogs

```

### requirements.txt
```
Flask==3.0.0
Flask-CORS==4.0.0
python-dateutil==2.8.2
click==8.1.7
Werkzeug==3.0.1
Jinja2==3.1.2
markdown==3.5.2
bleach==6.1.0
peewee==3.17.0
```
